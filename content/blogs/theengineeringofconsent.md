---
title: "The Engineering of Consent: Political Microtargeting"
date: 2024-04-08
draft: false
image: /images/aielectionposter.jpg
description: "The future of political advertising and online manipulation."
toc: true
---

### 1. What is Online Political Microtargeting?

With society becoming increasingly digitized (“the integration of multiple technologies into all aspects of daily life”) the resulting abundance of personal data and information that can be amassed about the individual has only served to be [exponentially magnified](https://firstmonday.org/ojs/index.php/fm/article/view/4991). Corresponding to this rapidly growing and valuable [‘data economy’](https://www.weforum.org/agenda/2017/09/the-value-of-data/), the use of personal data for political purposes has also risen, massively increasing the prevalence of data-driven political campaigns. Amongst the various tools and methods available to apply personal data towards political purposes, it is this posts’ view that online political microtargeting (OPMT) stands out, with its historically unprecedented usage yielding [ramifications](https://www.tandfonline.com/doi/full/10.1080/07393148.2015.1125119) for the rights to privacy; electoral fairness and on a broader scale fundamental [democratic processes](https://policyreview.info/data-driven-elections) and concepts.

But what is online political microtargeting and how does it impact upon you? OPMT can be described, under scholar [Gorton’s definition](https://www.tandfonline.com/doi/full/10.1080/07393148.2015.1125119) as:

> _“finely honed messages targeted at narrow categories of voters based on sophisticated combinatorial analysis of data garnered from individuals’ demographic characteristics and consumer and lifestyle habits”_

Put simply, online political microtargeting [“allows political players to send tailored messages to citizens in order to influence them.”](https://www.uva.nl/en/shared-content/faculteiten/en/faculteit-der-maatschappij-en-gedragswetenschappen/news/2020/07/microtargeting.html)

The below video offers a great explanation of how political microtargeting works, created by Cambridge Analytica, the (former) firm at the heart of an [election interference scandal](https://www.theguardian.com/news/series/cambridge-analytica-files).

{{< youtube lBgHrn-TrD8 >}}

### 2. Implications for Individual’s Privacy

The widespread use of OPMT, which requires the accumulation, synthesis and utilization of a massive amount of personal data brings with it major inter-connected implications for individual’s privacy. The storing and use of personal data inevitably leads to the risk of data breaches, an all to common occurrence, which severely undermines individual’s privacy, having [graver impacts](https://cdn.ttc.io/s/tacticaltech.org/Personal-Data-Political-Persuasion-How-it-works_print-friendly.pdf) when such data leaked is of political nature. One can look at the Republican Party’s 2017 [data breach](https://thehill.com/policy/cybersecurity/338383-data-on-198-million-us-voters-left-exposed-to-the-internet-by-rnc-data) of nearly 200 million US citizens personal political data to see that such a threat is very real and present, and is compounded by the fact that personal data can be used in [unpredictable and untoward novel ways](http://doi.org/10.18352/ulr.420). Data breaches, in addition to the mere collection of personal political data, also have broader implications for Democracy, resulting in [chilling effects](https://ssrn.com/abstract=2654213), if people suspect, or are certain, that their internet presence is being tracked and that they do not have adequate online privacy. Privacy is crucial for voters to autonomously and secretly cast their ballot (a cornerstone of the electoral process), but the advent of data-driven elections and OPMT “presents a new privacy-related threat”, one that “leverages personal information to influence choice” (_Big Data, Political Campaigning and the Law: Democracy and Privacy in the age of Micro-targeting, page 47)_. Adequate privacy is a necessity for the individual to prosper and be shielded from the tyranny of the majority, creating distinct public, quasi-public and private spaces that serve as a prerequisite for [democratic self rule](https://paulschwartz.net/wp-content/uploads/2019/01/VAND-SCHWARTZ.pdf).

### 3. Implications for Electoral Fairness

The usage of OPMT effects the balance of power between political parties, with the widespread usage of ‘big data’ morphing the political arena into a data-analytic environment with the ability to effectively sort, process and utilize data towards goals being limited to powerful data-rich incumbent institutions. The implications of this are two-fold. First, this environment favors larger, incumbent and moneyed political parties and candidates as a result of the costly nature of using ‘big data’ (although this cost can be argued to be decreasing with time), leading to political success within a democracy being determined by financial and data resources and the ability to use them to effectively microtarget voters. This places smaller and newer parties and candidates at serious [disadvantages](https://scholar.harvard.edu/files/todd_rogers/files/political_campaigns_and_big_data_0.pdf). Secondly, in such a political environment, centers of power are shifted to a [technocratic](https://utrechtlawreview.org/articles/10.18352/ulr.420) class of intermediaries that provide such services such as OPMT and the connection of political parties and the electorate, creating political ‘gatekeepers’ not subject to Democratic scrutiny or accountability.

### 4. Implications for civil discourse

The widespread use of OPMT undermines civil discourse, serving to exasperate and create political polarization, fragmenting the democratic concept of the public forum, through the creation of algorithmically manipulated ‘filter bubbles’, also known as ‘echo-chambers’.

> _We find ourselves in a filter bubble any time we’re only surrounded by views and opinions we agree with, while being sheltered from opposing perspectives. Filter bubbles distort our understanding of the world and hamper our ability to make balanced decisions._ **\-Eli Pariser, Author of** _**Filter Bubbles**_

If the marketplace of ideas becomes fragmented, with the presence of ‘filter bubbles’ leading voters to exclusively concern themselves with political issues that are most relevant to them, public discourse and civil debate will undoubtedly suffer. Voter turnout, although possibly being increased due to this personalized advertising, would revolve around protecting and promoting individualized interests rather than the interests of the voting individuals placed in the context of the whole political community.

In addition, voters deemed to be unsusceptible or unable to be persuaded can be eliminated/ignored as advertising targets, creating a ‘form of categorical inequality in the public sphere’. OPMT further facilitates the fracturing of broadly engaging political topics into ‘wedge issues’ with political entities being able to ‘dog-whistle’ certain positions to sympathizers while simultaneously hiding them from political opponents. Such an example of this would be during the 2018 Brazilian elections with the campaign of Jair Bolsonaro’s use of WhatsApp to microtarget voters arguably promoting political radicalization and polarization leading to the advent of what has been described as [‘digital populism’.](https://www.researchgate.net/publication/338719508_WhatsApp_and_political_instability_in_Brazil_targeted_messages_and_political_radicalisation)

The threat of foreign actors utilizing OPMT with the aim of electoral interference is also one to [consider](https://www.ivir.nl/publicaties/download/MaastrichtJournalofEuropeanandComparativeLaw_2021_6.pdf). Foreign actors already use popular [social media platforms](https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2019/09/CyberTroop-Report19.pdf) in an attempt to manipulate and subvert democratic processes with the increasing use of microtargeting, based on easily purchasable and obtainable personal data, proving to be an effective tool to sow disinformation.

> _One of the greatest dangers of political microtargeting is that a voters political opinion can be influenced and altered. Political parties can make countless promises to a specific groups of voters and can hide their personalized stance from the general public. This can lead to very different expectations in voters, which politics can never live up to. The result is a polarized society, and individual parties can create advantages for themselves in the election campaign by making contradictory promises._ **\-[noyb.eu](https://noyb.eu/en/political-microtargeting-facebook-election-promise-just-you)**

### 5. The Engineering of Consent

Leading on from this is perhaps the most dangerous effect that the use of big data and analytical tools such as OPMT brings for Democracy; namely rendering voters manipulable, creating, as [Tufekci](https://firstmonday.org/ojs/index.php/fm/article/view/4901) describes with reference to the ‘father of public relations’ [Edward Bernays](https://archive.nytimes.com/www.nytimes.com/books/98/08/16/specials/bernays-obit.html), ‘more effective- and less transparent- ["engineering of consent"](http://www.fraw.org.uk/data/politics/bernays_1947.pdf) in the public sphere.’ Through personalized targeting and the use of ‘wedge issues’, political campaigns can be obscure on significant but broadly relevant topics within political discourse while campaigning with vigor and in secrecy on issues that can muster small, but vital voting demographics. As microtargeting is individualized, political messages distributed in such a manner will not be able to be countered and debated through civil discourse. Through the use of ‘cognitive nudges’, as explained by cyber-security researcher Bruce Schneier in _A Hackers Mind_, the human brain can effectively be ‘hacked’ with microtargeted content, in order to shape opinions, beliefs and to persuade, especially without necessary transparency. Democracy as a workable concept would arguably fall apart if the legitimacy of those elected was to be achieved through ‘tailored, fine-tuned messaging’ manufacturing the consent of the governed.

> _“The conscious and intelligent manipulation of the organized habits and opinions of the masses is an important element in democratic society. Those who manipulate this unseen mechanism of society constitute an invisible government which is the true ruling power of our country.”_ **\- Edward L. Bernays, [Propaganda](https://archive.org/details/in.ernet.dli.2015.275553/mode/2up)**

I would highly recommend the below four part series by the BBC that delves into the ideas of Edward Bernays, amongst others, and how they have aided in the ‘engineering of consent’ to shape the current mass consumerist society we live in through the start of psychology-driven advertising campaigns in the 1950’s. Also accessible [here](https://thoughtmaybe.com/the-century-of-the-self/) in case of YouTube removal or if you do not want to use that service.

{{< youtube fEsPOt8MG7E >}}

### 6. The Future of Political Advertising

[Efforts](https://www.congress.gov/bill/117th-congress/house-bill/4955) to [curb](https://edps.europa.eu/data-protection/our-work/publications/opinions/edps-opinion-proposal-regulation-transparency-and_en) the use of political microtargeting online are on the [rise](https://edri.org/our-work/whoreallytargetsyou-political-microtargeting-cant-be-ignored-by-the-dsa/). However, focus on this specific use of personal data for electoral purposes should not overshadow similar but more advanced data practices that will certainly degrade political discourse and democratic processes. As the technical capabilities and scope of Artificial Intelligence increases and the power afforded to those who wield it serves to be magnified, the political domain online will become increasingly hard to navigate effectively. Online political microtargeting is evidently a [common occurrence](https://noyb.eu/en/political-microtargeting-facebook-election-promise-just-you), but the concepts and ideas behind the practice can be used in a multitude of more deceptive and insidious ways. One such example would be “Persona bots’’, or Artificial Intelligence programs posing as real human users on social media platforms and online forums/ groups. These programs won’t need to constantly spout propaganda and political messaging, instead acting as normal users with normal online activity which on occasion will post political content in an attempt to sway public opinion.

I will end with a short video from VICE News that really drives the point home. For now all the best and have a brilliant day!

{{< youtube ZP3kLe_3uLo >}}

* * *

_One persona bot can’t move public opinion, but what if there were thousands of them? Millions? … AI has the potential to make the future supply of disinformation spreaders infinite._ **\-Bruce Schneier, A Hackers Mind: How the powerful bend society’s rules and how to bend them back**

* * *
