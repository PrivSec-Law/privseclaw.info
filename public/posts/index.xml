<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Privacy, Security and the Law</title>
    <link>http://localhost:1313/posts/</link>
    <description>Recent content on Privacy, Security and the Law</description>
    <image>
      <title>Privacy, Security and the Law</title>
      <url>http://localhost:1313/privseclaw.png</url>
      <link>http://localhost:1313/privseclaw.png</link>
    </image>
    <generator>Hugo -- 0.126.2</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Jul 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>FUTO Keyboard Review: An Android Keyboard that is Private and Functional</title>
      <link>http://localhost:1313/posts/futokeyboard/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/futokeyboard/</guid>
      <description>If you use Android your keyboard could be a security and privacy risk. Here is why you should use FUTO Keyboard instead!</description>
      <content:encoded><![CDATA[<h3 id="your-android-keyboard-is-most-likely-spying-on-you">Your Android Keyboard is Most Likely Spying on You</h3>
<p>If you are using an Android device it is possible that your keyboard application is highly insecure and spying on you.</p>
<p>If you are using a third party keyboard (one that is not provided by default on your phone&rsquo;s operating system) this risk is highly likely. This is because most third party keyboard applications offer much more than simple text input. Personalized text prediction and auto correct are often delivered through your personal key inputs (how and what you type) being uploaded to the keyboard provider&rsquo;s servers. While making your life more convenient, <a href="https://www.howtogeek.com/335428/smartphone-keyboards-are-a-privacy-nightmare/#why-keyboards-are-so-dangerous">this is a privacy nightmare</a>.</p>
<p>Think about all the things that you have typed into your phone&rsquo;s keyboard: highly intimate messages to loved ones and friends; sensitive medical records and confidential business information. You do not want this sort of information leaving your device and being sent to another party&rsquo;s servers. Why?</p>
<p>Because the keyboard app you use may be malicious (malware deliberately designed to spy on you). In 2022 Google removed many malicious apps, including keyboards, that collectively had been downloaded a <a href="https://wp.nyu.edu/itsecurity/2022/07/29/android-users-confirm-you-dont-have-malicious-apps-on-your-device/">staggering 10 million+ times.</a></p>
<p>Furthermore, even if the keyboard application you use is not deliberately and actively malicious, you still cannot trust it to keep your information secure and private. Some examples:</p>
<blockquote>
<p><em>&ldquo;SwiftKey (a Microsoft product) users started reporting that their keyboard was suggesting random foreign words and even unfamiliar email addresses.&rdquo;</em> - <a href="https://www.androidauthority.com/swiftkey-suspends-service-data-leak-706680/"><strong>SwiftKey suspends cloud syncing after data leak, Android Authority</strong></a></p>
</blockquote>
<blockquote>
<p><em>&ldquo;A team of security researchers at the Kromtech Security Center has discovered a massive trove of personal data belonging to more than 31 million users of the popular virtual keyboard app, AI.type, accidentally leaked online for anyone to download without requiring any password.&rdquo;</em> - <a href="https://thehackernews.com/2017/12/keyboard-data-breach.html"><strong>Massive Breach Exposes Keyboard App that Collects Personal Data On Its 31 Million Users, The Hacker News</strong></a></p>
</blockquote>
<p>These risks are not exclusively limited to third party keyboard applications either. A recent investigation by the University of Toronto&rsquo;s Citizen Lab found that <a href="https://www.technologyreview.com/2024/04/24/1091740/chinese-keyboard-app-security-encryption/">&ldquo;almost every Chinese keyboard app has a security flaw that reveals what users type,&rdquo;</a> leaving nearly 1 billion people &ldquo;vulnerable to eavesdropping,&rdquo; potentially by the Five Eyes (an intelligence gathering alliance between the USA, UK, Australia, New Zealand and Canada).</p>
<blockquote>
<p><em>&ldquo;We analyzed the security of cloud-based pinyin keyboard apps from nine vendors — Baidu, Honor, Huawei, iFlytek, OPPO, Samsung, Tencent, Vivo, and Xiaomi — and examined their transmission of users’ keystrokes for vulnerabilities.&rdquo;</em></p>
<p><em>&ldquo;Our analysis revealed critical vulnerabilities in keyboard apps from eight out of the nine vendors in which we could exploit that vulnerability to completely reveal the contents of users’ keystrokes in transit. Most of the vulnerable apps can be exploited by an entirely passive network eavesdropper.&rdquo;</em></p>
<p><em>&ldquo;we estimate that up to one billion users are affected by these vulnerabilities. Given the scope of these vulnerabilities, the sensitivity of what users type on their devices, the ease with which these vulnerabilities may have been discovered, and that the Five Eyes have previously exploited similar vulnerabilities in Chinese apps for surveillance, it is possible that such users’ keystrokes may have also been under mass surveillance.&rdquo;</em> - <a href="https://citizenlab.ca/2024/04/vulnerabilities-across-keyboard-apps-reveal-keystrokes-to-network-eavesdroppers/"><strong>The not-so-silent type, Vulnerabilities across keyboard apps reveal keystrokes to network eavesdroppers, Citizen Lab</strong> </a></p>
</blockquote>
<p>All of this raises the question. Why does your phone&rsquo;s keyboard application need an internet connection? I&rsquo;m going to hazard a guess that its because these companies want to extract your personal information for profit. The internet&rsquo;s business model is <a href="https://www.theguardian.com/books/2019/oct/04/shoshana-zuboff-surveillance-capitalism-assault-human-automomy-digital-privacy">Surveillance Capitalism</a> after all!</p>
<p>This is where <a href="https://keyboard.futo.org/">FUTO Keyboard</a> comes in!</p>
<h3 id="about-futo">About FUTO</h3>
<p>Futo is an organization that describes itself as:</p>
<blockquote>
<p><em>&ldquo;an organization dedicated to developing, both through in-house engineering and investment, technologies that frustrate centralization and industry consolidation.&rdquo;</em> - <strong><a href="https://futo.org/about/what-is-futo/">What is FUTO?</a></strong></p>
</blockquote>
<p>with the mission statement:</p>
<blockquote>
<p><em>&ldquo;Computers should belong to you, the people. We develop and fund technology to give them back.&rdquo;</em></p>
</blockquote>
<p>It was founded in 2021 by Eron Wolf, an 18 year Silicon Valley veteran and billionaire who has become disillusioned with the current oligopolistic grip Big Tech has over our digital lives.</p>
<blockquote>
<p><em>&ldquo;Through a combination of in-house engineering projects, targeted investments, generous grants, and multi-media public education efforts, we will free technology from the control of the few&rdquo;</em></p>
</blockquote>
<p>Amongst many other offerings the organization has created a private and secure keyboard application free to download and use.</p>
<h3 id="installation-and-setup">Installation and Setup</h3>
<p>Installing FUTO Keyboard on your Android device is extremely easy. You can choose to install it from the <strong><a href="https://play.google.com/store/apps/details?id=org.futo.inputmethod.latin.playstore">Google Play Store,</a></strong> alternative Android app store <strong><a href="https://app.futo.org/fdroid/repo/">F-Droid,</a></strong> or through Obtanium using their <strong><a href="https://github.com/futo-org/android-keyboard/releases">Github repository.</a></strong></p>
<p>Once installed, open the app and click through the popups which will ask you to set FUTO Keyboard as your default Android keyboard.</p>
<h3 id="features">Features</h3>
<h4 id="privacy-respecting">Privacy Respecting</h4>
<p>FUTO Keyboard does not connect to the internet and it does not request or require network privileges. This means that the application is incapable of sending your keystrokes, inputs and voice data to any party. I verified this myself using GrapheneOS, an operating system which allows for more granular control of application network permissions compared to normal Android. Upon opening the permissions section in my phone&rsquo;s settings it was clear that FUTO Keyboard does not connect to the internet. See below (microphone permissions are an optional permission if you want to use the voice to text feature):</p>
<figure>
    <img loading="lazy" src="/images/futokeyboardpermissions.jpg#center"
         alt="text" width="50%"/> 
</figure>

<h4 id="everything-you-need-from-a-keyboard-app">Everything you Need from a Keyboard App</h4>
<p>FUTO Keyboard has a wide range of features that has everything you could need from a keyboard application:</p>
<ul>
<li>A wide variety of light and dark themes available for use that all look great.</li>
<li>All the emoji support you may need.</li>
<li>A clipboard manager to manage copied text and images.</li>
<li>Many typing preferences including emoji suggestions, text prediction and swipe typing.</li>
<li>Support for many languages with an easy way to swap between them in the keyboard.</li>
<li>Voice to text support .</li>
<li>Support for imported voice to text models which can be discovered through a link in the application.</li>
</ul>
<p>Here is what the keyboard itself looks like:</p>
<figure>
    <img loading="lazy" src="/images/futokeyboard.jpg#center"
         alt="text" width="50%"/> 
</figure>

<p>And the application&rsquo;s settings:</p>
<figure>
    <img loading="lazy" src="/images/futokeyboardsettings.jpg#center"
         alt="text" width="50%"/> 
</figure>

<h4 id="source-code-is-available-and-verifiable">Source Code is Available and Verifiable</h4>
<p>In the spirit of FUTO&rsquo;s mission the source code for the application is available to see in what the organization calls &ldquo;source first&rdquo;, a new software licencing standard created by the organization. For all intents and purposes source first is open source, with code being publicly viewable and verifiable and individuals being able to download, view, modify and redistribute it for personal use. How this differs from traditional open source licencing is that it <a href="https://futo.org/about/futo-statement-on-opensource/">&ldquo;will not force programmers to let others, especially the tech oligopoly, profit from their work for free.&rdquo;</a></p>
<h4 id="honor-based-payment">Honor Based Payment</h4>
<p>FUTO has chosen to implement an honor based payment method for the application. Choosing to not pay for FUTO Keyboard and using it during the eternal free trial period will not impact your ability to use it or enjoy all the features. As put by Louis Rossman, a prominent Right to Repair activist and FUTO member, using it without paying <a href="https://www.youtube.com/watch?v=GYX92lLpZ20">&ldquo;will be between you and your god.&rdquo;</a></p>
<h3 id="final-remarks">Final Remarks</h3>
<p>With essentially everything you do on an Android smartphone making use of the keyboard it is great to have the peace of mind that it does not connect to the internet. Highly intimate messages typed to loved ones and friends, sensitive medical records and confidential business information all go through your keyboard application. They should be private and secure. I don&rsquo;t trust Google, Samsung, Motorola or Huawei in the slightest and neither should you. The record is very clear about their anti-consumer and surveillance based business models.</p>
<p>In place of these internet connected keyboard options, I would highly recommend FUTO&rsquo;s offer instead!</p>
<p>For more information about FUTO as an organization, its mission and the backing behind it see this below video:</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/ugkWm6XGWo8?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "futokeyboard"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>The AI Panic: Big Tech, Open-source and Monopoly Power</title>
      <link>http://localhost:1313/posts/bigtechandai/</link>
      <pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/bigtechandai/</guid>
      <description>Big Tech, billionaires and whole lot of Artificial Intelligence lobbying.</description>
      <content:encoded><![CDATA[<h3 id="the-existential-threat-of-ai">The Existential Threat of AI?</h3>
<p>There is currently a concerted effort to portray Artificial Intelligence developments as an <a href="https://www.wired.com/story/runaway-ai-extinction-statement/">extinction level risk to humanity, on par with a nuclear war and deadly pandemics.</a> AI experts, namely <a href="https://www.safe.ai/work/statement-on-ai-risk">leaders and CEO&rsquo;s from Big Tech and adjacent industries, certain academics</a> and billionaire backed philanthropy groups have all called for <a href="https://time.com/6280372/sam-altman-chatgpt-regulate-ai/">state intervention and regulation of their own industry.</a>  The mass media, quick to pick up on claims of the oncoming AI apocalypse, have regurgitated these claims from the experts, drumming up popular apprehension amongst the general public, elected officials and policy makers.</p>
<blockquote>
<p><em>&ldquo;My worst fears are that we—the field, the technology, the industry—cause significant harm to the world. I think that can happen in a lot of different ways&rdquo;</em> - <strong><a href="https://time.com/6280372/sam-altman-chatgpt-regulate-ai/">Sam Altman, &lsquo;Open&rsquo;AI</a></strong></p>
</blockquote>
<blockquote>
<p><em>&ldquo;If somebody builds a too-powerful AI, under present conditions, I expect that every single member of the human species and all biological life on Earth dies shortly thereafter&rdquo;</em> - <strong><a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">Eliezer Yudkowsky, Machine Intelligence Research Institute</a></strong></p>
</blockquote>
<p>Looking at these presented grave dangers from industry insiders and leaders it appears to me that something does not add up. AI is purported to have the potential to be catastrophic for the human race yet AI development has not been paused. Quite to the contrary it has <a href="https://www.cnbc.com/2024/02/09/openai-ceo-sam-altman-reportedly-seeking-trillions-of-dollars-for-ai-chip-project.html">accelerated at breakneck pace</a> as for-profit, Big Tech companies seek to cement and <a href="https://www.bloomberg.com/company/press/generative-ai-to-become-a-1-3-trillion-market-by-2032-research-finds/">expand</a> their market positions and develop ever more powerful AI models.</p>
<h3 id="two-visions-of-the-future-of-ai">Two Visions of the Future of AI</h3>
<p>There is a conflict playing out as to how AI is to be developed.</p>
<p>On one side there is the nexus of Big Tech, the <a href="https://www.youtube.com/watch?v=4oOCLIrB-0c">Surveillance Capitalists</a> and increasingly elements of <a href="https://www.theverge.com/2024/6/13/24178079/openai-board-paul-nakasone-nsa-safety">immense State power</a> which, as put eloquently by Zuboff, <a href="https://journals.sagepub.com/doi/10.1177/26317877221129290">&ldquo;constitute a sweeping political-economic institutional order that exerts oligopolistic control over most digital information and communication spaces, systems, and processes.&rdquo;</a> These entities would fashion themselves as a technological high priesthood, <a href="https://analyticsindiamag.com/openai-raises-alarm-over-open-source-ai-dangers/">gate-keeping the development</a> and <a href="https://openai.com/index/reimagining-secure-infrastructure-for-advanced-ai/">deployment</a> of AI as regulated, restricted and walled off behind their proprietary, nontransparent systems. This is not new. <a href="https://web.archive.org/web/20240105020753/https://www.cnet.com/tech/services-and-software/dead-and-buried-microsofts-holy-war-on-open-source-software/">Large technology corporations</a> and <a href="https://wiki.openrightsgroup.org/wiki/Crypto_Wars">States</a> have historically been opposed to open source and democratized technology as it challenges their institutional and monopoly powers within society.</p>
<p>On the other side, there are a growing number of individuals, companies (including some surprises such as <a href="https://www.theguardian.com/technology/2023/dec/05/open-source-ai-meta-ibm">Meta and IBM</a>) and parts of <a href="https://open.mozilla.org/letter/">civil society</a> that reject this view and see open sourced Artificial Intelligence as necessary for innovation and safety through transparency, effective competition and security. As seen with <a href="https://laion.ai/">LAION&rsquo;s</a> <a href="https://laion.ai/notes/letter-to-the-eu-parliament/">&ldquo;Call to Protect Open-Source AI in Europe,&rdquo;</a> the touted benefits of open-source AI are security, competition and safety:</p>
<blockquote>
<p><em>&ldquo;First, <strong>open-source AI promotes safety through transparency</strong>. Open-sourcing data, models, and workflows enables researchers and authorities to audit the performance of a model or system; develop interpretability techniques; identify risks; and establish mitigations or develop anticipatory countermeasures. Second, <strong>open-source AI promotes competition</strong>. Small to medium enterprises across Europe can build on open-source models to drive productivity, instead of relying on a handful of large firms for essential technology. Finally, <strong>open-source AI promotes security</strong>. Public and private sector organizations can adapt open-source models for specialized applications without sharing private or sensitive data with a proprietary firm&rdquo;</em></p>
</blockquote>
<p>The rest of this blog post concerns itself primarily with the second point raised by LAION which, in my view, is the primary reason current Big Tech AI incumbents are pushing so heavily for regulation. I&rsquo;m not saying attempted regulatory capture to erect barriers to entry and crush competition but&hellip;</p>
<h3 id="big-tech-billionaires-and-whole-lot-of-lobbying">Big Tech, Billionaires and Whole Lot of Lobbying</h3>
<p>In the United States, Artificial Intelligence related lobbying has spiked dramatically in the past two years. As reported in <a href="https://www.cnbc.com/2024/02/02/ai-lobbying-spikes-nearly-200percent-as-calls-for-regulation-surge.html">CNBC</a>, AI lobbying efforts spiked 185% from 2022 to 2023 with over 450 organizations participating in efforts to influence US Federal legislation. This spike corresponded with growing calls for AI regulation and the Biden administration&rsquo;s push to codify such rules into law. A whole host of corporations and industries ranging from the expected Big Tech and AI to pharmaceuticals, insurance, finance, telecommunications and data brokerages are involved in these efforts. Even Disney is splashing their cash on the AI scene. As of February 2024 these entities have spent in excess of $950 million in lobbying efforts. But that is not all.</p>
<p>There are billionaire-backed networks of AI advisers that have &ldquo;taken over Washington&rdquo; as <a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362">Politico</a> so succinctly puts it. These networks are &ldquo;spread across Congress, federal agencies and think tanks&rdquo; with one of them essentially funneling Big Tech money <a href="https://www.politico.com/news/2023/12/03/congress-ai-fellows-tech-companies-00129701">&ldquo;through a science nonprofit to help pay the salaries of AI staffers in Congress.&rdquo;</a> This blog post highlights two of these networks, however it must be acknowledged these are simply just two good examples of the increasing influence Big Tech is having on AI policy within the US Federal government.</p>
<p>The first organization of note is Open Philanthropy, primarily funded by <a href="https://www.openphilanthropy.org/about-us/">Dustin Moskovitz:</a> billionaire Facebook co-founder and CEO of Asana who also happens to be among the Biden campaign&rsquo;s <a href="https://www.opensecrets.org/2020-presidential-race/joe-biden/contributors?id=N00001669">biggest donors</a>. Through the <a href="https://horizonpublicservice.org/about-us/">Horizon Institute for Public Service</a>, Open Philanthropy funds the salaries of key individuals working in key bodies responsible for AI rule making:</p>
<blockquote>
<p><em>&ldquo;Current and former Horizon AI fellows with salaries funded by Open Philanthropy are now working at the Department of Defense, the Department of Homeland Security and the State Department, as well as in the House Science Committee and Senate Commerce Committee, two crucial bodies in the development of AI rules. They also populate key think tanks shaping AI policy, including the RAND Corporation and Georgetown University’s Center for Security and Emerging Technology, according to the Horizon web site. In 2022, Open Philanthropy <a href="https://www.openphilanthropy.org/grants/open-philanthropy-technology-policy-fellowship-2022/">set aside nearly $3 million to pay for</a> what ultimately became the initial cohort of Horizon fellows.&rdquo;</em> - <a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362"><strong>How a billionaire-backed network of AI advisers took over Washington, POLITICO</strong></a></p>
</blockquote>
<p>The second group of note is a <a href="https://www.aaas.org/news/stpf-ai-cohort">&ldquo;rapid response cohort&rdquo;</a> of AI fellows (lobbyists) responsible for supporting &ldquo;leaders in Congress as they craft legislation, in particular policies related to emerging opportunities and challenges with AI.&rdquo; Run by the American Association for the Advancement of Science with <a href="https://www.politico.com/news/2023/12/03/congress-ai-fellows-tech-companies-00129701">&ldquo;substantial support from Microsoft, &lsquo;Open&rsquo;AI, Google, IBM and Nvidia,&rdquo; </a> this cohort of lobbyists exerts considerable influence on Congressional AI rule making.</p>
<blockquote>
<p><em>&ldquo;Alongside the Open Philanthropy fellows — and hundreds of outside-funded fellows throughout the government, including many with links to the tech industry — the six AI staffers in the industry-funded rapid response cohort are helping shape how key players in Congress approach the debate over when and how to regulate AI, at a time when many Americans are deeply skeptical of the industry.&rdquo;</em> - <a href="https://www.politico.com/news/2023/12/03/congress-ai-fellows-tech-companies-00129701"><strong>Key Congress staffers in AI debate are funded by tech giants like Google and Microsoft, POLITICO</strong></a></p>
</blockquote>
<p>This immense lobbying effort is not limited to Washington, though due to the United State&rsquo;s political system this is perhaps the best showcase of Big Tech&rsquo;s influence in action.</p>
<p>Across the Atlantic, Rishi Sunak&rsquo;s government, at first nonchalant about the increasing usage and development of AI has had the dangers of <a href="https://www.politico.eu/article/rishi-sunak-artificial-intelligence-pivot-safety-summit-united-kingdom-silicon-valley-effective-altruism/">&ldquo;existential risk pushed right up on the policy agenda&rdquo;</a> by key government advisors linked heavily to AI companies and Big Tech.</p>
<p>In the European Union, the recently passed <a href="https://artificialintelligenceact.eu/">&ldquo;AI Act&rdquo;</a> was heavily lobbied by <a href="https://time.com/6273694/ai-regulation-europe/">Big Tech.</a> Lobbying efforts, such as those by &lsquo;OpenAI&rsquo;, were focused on watering down the ways in which the law would burden the company. In multiple cases, <a href="https://time.com/6288245/openai-eu-lobbying-ai-act/">&quot;&lsquo;Open&rsquo;AI proposed amendments that were later made to the final text of the EU law.&quot;</a> This is in seeming direct contradiction with the statements released by these companies about the need for regulation. Hypocrisy from Big Tech and their executives? Who would have thought?</p>
<blockquote>
<p><em>“What they’re saying is basically: trust us to self-regulate,” says Daniel Leufer, a senior policy analyst focused on AI at Access Now’s Brussels office. “It’s very confusing because they’re talking to politicians saying, ‘Please regulate us,’ they’re boasting about all the safety stuff that they do, but as soon as you say, ‘Well, let’s take you at your word and set that as a regulatory floor,’ they say no.”</em> - <a href="https://time.com/6288245/openai-eu-lobbying-ai-act/"><strong>OpenAI Lobbied the E.U. to Water Down AI Regulation, TIME</strong> </a></p>
</blockquote>
<p>It is undeniable that there exists considerable influence from Big Tech in Artificial Intelligence regulation and policy. Regardless of your views on these companies, history is littered with examples of large powerful corporations, Big Tech or otherwise, pursuing their profit incentive through legislative capture at the expense of common good. Why should these companies act any different?</p>
<blockquote>
<p><em>&ldquo;Tim Stretton, director of the congressional oversight initiative at the nonpartisan watchdog Project On Government Oversight, said it’s “never great when corporations are funding, essentially, congressional staffers.” He said the money from five leading AI firms, suggests an improper level of tech industry influence.&rdquo;</em> - <a href="https://www.politico.com/news/2023/12/03/congress-ai-fellows-tech-companies-00129701"><strong>Key Congress staffers in AI debate are funded by tech giants like Google and Microsoft, POLITICO</strong></a></p>
</blockquote>
<blockquote>
<p>Sen. Dick Durbin (D., Ill.) remarked that he could not recall a time when representatives for private sector entities had ever pleaded for regulation. - <strong><a href="https://time.com/6280372/sam-altman-chatgpt-regulate-ai/">OpenAI CEO Sam Altman Asks Congress to Regulate AI, TIME</a></strong></p>
</blockquote>
<h3 id="effective-altruism-and-the-focus-on-existential-threats">Effective Altruism and the Focus on Existential Threats</h3>
<p>The intense lobbying efforts on the part of Big Tech to influence the AI regulatory agenda appear to be heavily linked to &ldquo;effective altruism&rdquo; (EA): the controversial Silicon Valley ideology and movement that, amongst other things seems to <a href="https://www.politico.eu/article/rishi-sunak-artificial-intelligence-pivot-safety-summit-united-kingdom-silicon-valley-effective-altruism/">&ldquo;advocate policy that’s focused on the distant future rather than the here-and-now.&rdquo;</a> According to industry insiders the ideology is now <a href="https://web.archive.org/web/20240108214418/https://www.wired.com/story/effective-altruism-artificial-intelligence-sam-bankman-fried/">&ldquo;driving the research agenda in the field of artificial intelligence (AI), creating a race to proliferate harmful systems, ironically in the name of “AI safety.&rdquo;</a></p>
<blockquote>
<p><em>&ldquo;Some of the billionaires who have committed significant funds to this goal include <a href="https://web.archive.org/web/20240108214418/https://twitter.com/elonmusk/status/495759307346952192">Elon Musk</a>, <a href="https://web.archive.org/web/20240108214418/https://forum.effectivealtruism.org/posts/wFC3axfuwABHmoQ9H/the-vitalik-buterin-fellowship-in-ai-existential-safety-is">Vitalik Buterin</a>, <a href="https://web.archive.org/web/20240108214418/https://www.openphilanthropy.org/research/co-funding-partnership-with-ben-delo/">Ben Delo</a>, <a href="https://web.archive.org/web/20240108214418/https://www.cser.ac.uk/team/jaan-tallinn/">Jaan Tallinn</a>, <a href="https://web.archive.org/web/20240108214418/https://www.ft.com/content/abc942cc-5fb3-11e4-8c27-00144feabdc0">Peter Thiel</a>, <a href="https://web.archive.org/web/20240108214418/https://www.ft.com/content/15ffce3b-cee3-44ad-b961-e22459b7b7b2">Dustin Muskovitz</a>, and <a href="https://web.archive.org/web/20240108214418/https://inside.com/ai/posts/anthropic-raises-580m-from-bankman-fried-tallinn-for-safer-ai-282609">Sam Bankman-Fried</a>, who was one of <a href="https://web.archive.org/web/20240108214418/https://www.washingtonpost.com/technology/2022/11/17/effective-altruism-sam-bankman-fried-ftx-crypto/">EA’s largest funders</a> until the recent bankruptcy of his FTX cryptocurrency platform. As a result, all of this money has shaped the field of AI and its priorities in ways that harm people in marginalized groups while purporting to work on “beneficial artificial general intelligence” that will bring techno utopia for humanity. This is yet another example of how our technological future is not a linear march toward progress but one that is determined by those who have the money and influence to control it.&rdquo;</em> - <a href="https://web.archive.org/web/20240108214418/https://www.wired.com/story/effective-altruism-artificial-intelligence-sam-bankman-fried/"><strong>Effective Altruism Is Pushing a Dangerous Brand of ‘AI Safety’</strong> </a></p>
</blockquote>
<p>The above mentioned organizations, such as Open Philanthropy, have <a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362">significant ties the movement</a>, with many AI thinkers seeing the existential AI threats that EA proponents push being &ldquo;science-fiction concerns far removed from the current AI harms&rdquo; that should be addressed, resulting in the &ldquo;steering of policy conversation away from more pressing issues - including topics some leading AI firms might prefer to keep off the policy agenda.&rdquo;</p>
<blockquote>
<p><em>&ldquo;The network’s fixation on speculative harms is “almost like a caricature of the reality that we’re experiencing,” said Deborah Raji, an AI researcher at the University of California, Berkeley, who attended last month’s AI Insight Forum in the Senate. She worries that the focus on existential dangers will steer lawmakers away from addressing risks that today’s AI systems already pose, including their tendency to inject bias, spread misinformation, threaten copyright protections and weaken personal privacy.&rdquo;</em> - <a href="https://www.politico.com/news/2023/10/13/open-philanthropy-funding-ai-policy-00121362"><strong>How a billionaire-backed network of AI advisers took over Washington, POLITICO</strong></a></p>
</blockquote>
<h3 id="extensively-lobbied-regulations-benefit-incumbents">Extensively Lobbied Regulations Benefit Incumbents</h3>
<h4 id="the-effects-of-such-lobbying">The Effects of Such Lobbying</h4>
<p>With the influence of Big Tech AI incumbents and the ideas of &rsquo;existential threats&rsquo; evidently having a massive role to play in the drafting of AI regulation, one could expect policy proposals to benefit the interests of such parties.</p>
<p>So lets have a look at an example of a legislative proposal: namely one bipartisan bill proposed in the United States by <a href="https://www.blumenthal.senate.gov/newsroom/press/release/blumenthal-and-hawley-announce-bipartisan-framework-on-artificial-intelligence-legislation">U.S. Senators Richard Blumenthal (D-CT) and Josh Hawley (R-MO), Chair and Ranking Member of the Senate Judiciary Subcommittee on Privacy, Technology, and the Law.</a> Within this proposed legislative framework the key takeaways are:</p>
<ul>
<li>&ldquo;The establishment of a licencing regime administered by an independent oversight body&rdquo; which AI developers working on sophisticated general purpose models would be required to register with the body. In this context a licencing scheme is just another word for permission.</li>
<li>The above mentioned body would &ldquo;ensure legal accountability for harms&rdquo; through the requirement of AI companies being held liable when harms are caused through the use of their models.</li>
</ul>
<p>This legislation echoes the type of regulation called for by the likes of &lsquo;Open&rsquo;AI in the May 2023 Congressional hearing on AI.</p>
<blockquote>
<p><em>&ldquo;he (Sam Altman) supported the creation of a federal agency that can grant licenses to create AI models above a certain threshold of capabilities, and can also revoke those licenses if the models don’t meet safety guidelines set by the government.&rdquo;</em> - <a href="https://time.com/6280372/sam-altman-chatgpt-regulate-ai/"><strong>OpenAI CEO Sam Altman Asks Congress to Regulate AI, TIME</strong></a></p>
</blockquote>
<p>This establishment of a strict liability regime based upon existential harms caused by AI models would ensure that only large, already established incumbent companies would have the financial and technical ability to comply with the law, while new startups and alternative non corporate structures (such as open-source) would face serious barriers to entry. Such a legislative proposal, if passed into law, would almost certainly pose limits, if not entirely restrict the legal development of open-source AI while leaving only the big, closed and proprietary models standing.</p>
<h4 id="opposition-to-the-current-regulatory-narrative">Opposition to the Current Regulatory Narrative</h4>
<p>This is a view shared by a growing number of key AI figures, academics and technologists. Perhaps the most notable of these is <a href="https://www.andrewng.org/">Andrew Ng:</a> Stanford Professor; machine learning teacher to &lsquo;Open&rsquo;AI CEO Sam Altman; co-founder of Google Brain and a globally recognized leader in Artificial Intelligence. He is of the belief that notions of Artificial Intelligence leading to the extinction of the human race is <a href="https://web.archive.org/web/20231030062420/https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz">&ldquo;a lie being promulgated by big tech in the hope of triggering heavy regulation that would shut down competition in the AI market&rdquo;</a> and a <a href="https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3">big proponent of open-source AI development.</a></p>
<blockquote>
<p><em>&ldquo;Andrew Ng said that the “bad idea that AI could make us go extinct” was merging with the “bad idea that a good way to make AI safer is to impose burdensome licensing requirements” on the AI industry.&rdquo;</em> - <a href="https://web.archive.org/web/20231030062420/https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz"><strong>Google Brain founder says big tech is lying about AI extinction danger, Financial Review</strong> </a></p>
</blockquote>
<p>I would highly <a href="https://www.ft.com/content/2dc07f9e-d2a9-4d98-b746-b051f9352be3">advise a read of the interview with Andrew Ng from the Financial Times,</a> of which I will take key snippets. (Extracts copied below are for nonprofit educational purposes under <a href="https://copyright.gov/title17/92chap1.html#107">Section 107 of the Copyright Act: Fair Use</a> and <a href="https://www.ippt.eu/legal-texts/copyright-information-society-directive/article-5">Article 5: Information Society Directive</a>)</p>
<blockquote>
<p><em>&ldquo;Open-source software’s getting easy enough for most people to just install it and use it now. And it’s not that I’m obsessed about regulation — but if some of the regulators have their way, it’d be much harder to let open-source models like this keep up.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Some proposals, for instance, have reporting or even licensing requirements for LLMs. And while the big tech companies have the bandwidth to deal with complex compliance, smaller businesses just don’t.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;When I think about the AI human extinction scenarios, when I speak with people who say they’re concerned about this, their concerns seem very vague. And no one seems to be able to articulate exactly how AI could kill us all.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;There is also some chance that is absolutely non-zero of our radio signals causing aliens to find us and wipe us all out. But the chance is so small that we should not waste disproportionate resources to defend against that danger. And what I’m seeing is that we are spending vastly disproportionate resources against a risk that is almost zero.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Multiple companies are overhyping the threat narrative. For large businesses that would rather not compete with open-source, there is an incentive. For some non-profits, there is an incentive to hype up fears, hype up phantoms, and then raise funding to fight the phantoms they themselves conjured. And there are also some individuals who are definitely commanding more attention and larger speaker fees because of fear that they are helping to hype up. I think there are a few people who are sincere — mistaken but sincere — but on top of that there are significant financial incentives for one or multiple parties to hype up fear.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;When lots of people signed [the Center for AI Safety statement] saying AI is dangerous like nuclear weapons, <a href="https://www.ft.com/content/084d5627-5193-4bdc-892e-ebf9e30b7ea3">the media covered that</a>. When there have been much more sensible statements — for example, <a href="https://open.mozilla.org/letter/">Mozilla</a> saying that open source is a great way to ensure AI safety — almost none of the media cover that.&rdquo;</em></p>
</blockquote>
<p>Andrew Ng is not alone in these views. In addition to the <a href="https://laion.ai/notes/letter-to-the-eu-parliament/">LAION</a> open letter addressed to the European Parliament calling for the protection of open-source AI that was referred to previously, Mozilla has also released a <a href="https://open.mozilla.org/letter/">Joint Statement on AI Safety and Openness</a> signed by a varied range of companies, civil society organisations and leading individuals in the realms of computer science, engineering, journalism and policy making.</p>
<blockquote>
<p><em>&ldquo;Yes, openly available models come with risks and vulnerabilities — AI models can be abused by malicious actors or deployed by ill-equipped developers. However, we have seen time and time again that the same holds true for proprietary technologies — and that increasing public access and scrutiny makes technology safer, not more dangerous. The idea that tight and proprietary control of foundational AI models is the only path to protecting us from society-scale harm is naive at best, dangerous at worst.&rdquo;</em> - <a href="https://open.mozilla.org/letter/"><strong>Joint Statement on AI Safety and Openness, Mozilla</strong></a></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Further, history shows us that quickly rushing towards the wrong kind of regulation can lead to concentrations of power in ways that hurt competition and innovation. Open models can inform an open debate and improve policy making. If our objectives are safety, security and accountability, then openness and transparency are essential ingredients to get us there.</em>&rdquo; - <a href="https://open.mozilla.org/letter/"><strong>Joint Statement on AI Safety and Openness, Mozilla</strong></a></p>
</blockquote>
<p>In addition to this, there is growing research highlighting the concerns of Big Tech influenced regulation on open-source AI development and the resultant negative impacts upon competition such as this piece by the Carnegie Endowment:</p>
<blockquote>
<p><em>&ldquo;policy measures that address only speculative superintelligence concerns (and not more evolutionary AI policy challenges) are especially likely to impose steep costs in exchange for minimal benefits.&rdquo;</em> - <a href="https://carnegieendowment.org/posts/2023/09/how-hype-over-ai-superintelligence-could-lead-policy-astray?lang=en"><strong>How Hype Over AI Superintelligence Could Lead Policy Astray, Carnegie Endowment</strong> </a></p>
</blockquote>
<p>and the peer reviewed paper from Stanford in the George Washington Law Review: <em><a href="https://law.stanford.edu/publications/ai-regulation-has-its-own-alignment-problem-the-technical-and-institutional-feasibility-of-disclosure-registration-licensing-and-auditing/">&ldquo;AI Regulation Has Its Own Alignment Problem: The Technical and Institutional Feasibility of Disclosure, Registration, Licensing, and Auditing&rdquo;</a></em>:</p>
<blockquote>
<p><em>&ldquo;the potential of licensing to undermine competition, raise costs to consumers, enable industry capture, and gatekeep professions indicates AI licensing would create horizontal misalignment&hellip; AI licensing that places significant pre- and post-market burdens on companies may be prohibitively costly for smaller developers.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Licensing the development or deployment of AI thus has the potential to concentrate economic power in the hands of a few large companies&hellip; Licensing may heighten market concentration by advantaging more established incumbents who can more easily bear the licensing costs.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Concentration of market power could even exacerbate other harms arising from AI or undermine human values and regulatory objectives these policies aim to promote.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;Licensing also creates tradeoffs between openness and control. Open access may provide for less control by enabling individuals with bad intentions or insufficient training to more easily access resources, but it may also increase the likelihood that critical issues with the technology are identified after release. Licensing may make it harder for users to expose harms, especially considering how openness provided mechanisms for discovering and addressing cybersecurity risks.&rdquo;</em></p>
</blockquote>
<blockquote>
<p><em>&ldquo;licensing regimes are particularly susceptible to capture. For example, research suggests that lobbying by physician interest groups is linked to a higher probability that a state will have occupational licensing in the healthcare industry. The potential for special interest groups to have outsized impact on AI licensing regimes is particularly worrisome given licensing may make the frontier of AI technology inaccessible to most.&rdquo;</em></p>
</blockquote>
<p>These views have not gone unnoticed. The European Union&rsquo;s landmark AI Act has <a href="https://www.europarl.europa.eu/legislative-train/theme-a-europe-fit-for-the-digital-age/file-regulation-on-artificial-intelligence">carve outs and exceptions for open-source AI development</a>. Only time will tell how far these exceptions go.</p>
<p>Given <a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">leaked documentation from a Google</a> engineer that warns it and &lsquo;Open&rsquo;AI could <a href="https://www.theguardian.com/technology/2023/may/05/google-engineer-open-source-technology-ai-openai-chatgpt">lose out to open-source</a> technology in the &lsquo;AI arms race&rsquo;, it is clear that Big Tech is concerned with the prospects of widely available open AI and is evidently lobbying hard for rules to be crafted to their benefit as an industry.</p>
<h4 id="law-enforcement-and-the-national-security-state-is-getting-their-way-as-well">Law Enforcement and the National Security State is Getting their Way as Well</h4>
<p>While not the main focus of this post, it is worthwhile to note that it is not just Big Tech and the AI industry that is trying to get/ getting their way when it comes to AI regulation and policy. Law enforcement and national security agencies, leaders and policy makers are also involved in setting the agenda. There is a clear <a href="https://www.opensecrets.org/revolving-door">revolving door</a> and incestuous relationship between the National Security State and the Big Tech Surveillance Capitalists, best exemplified by &lsquo;Open&rsquo;AI&rsquo;s recent <a href="https://www.theverge.com/2024/6/13/24178079/openai-board-paul-nakasone-nsa-safety">appointment</a> of former NSA Director and spook in chief Paul M. Nakasone to the position of the company&rsquo;s board and the &lsquo;Safety and Security Committee&rsquo;.</p>
<p>In the EU, civil society organizations have raised the alarm about vague terms, exceptions and carve outs that the AI Act affords to law enforcement and national security agencies allowing them to use AI and conduct biometric and facial recognition on a mass societal level. Some of these statements are linked below:</p>
<ul>
<li><a href="https://edri.org/our-work/eu-ai-act-fails-to-set-gold-standard-for-human-rights/">EU’s AI Act fails to set gold standard for human rights</a>, European Digital Rights</li>
<li><a href="https://edri.org/our-work/packed-with-loopholes-why-the-ai-act-fails-to-protect-civic-space-and-the-rule-of-law/">Packed with loopholes: Why the AI Act fails to protect civic space and the rule of law</a>, European Digital Rights and the European Center for Not-for-Profit Law</li>
<li><a href="https://edri.org/our-work/civil-society-statement-regulate-police-tech-ai-act/">EU lawmakers must regulate the harmful use of tech by law enforcement in the AI Act</a>, European Digital Rights</li>
<li><a href="https://www.accessnow.org/press-release/ai-act-failure-for-human-rights-victory-for-industry-and-law-enforcement/">The EU AI Act: a failure for human rights, a victory for industry and law enforcement</a>, Accessnow</li>
<li><a href="https://www.laquadrature.net/en/2024/05/22/with-the-ai-act-adopted-the-techno-solutionist-gold-rush-can-continue/">WITH THE AI ACT ADOPTED, THE TECHNO-SOLUTIONIST GOLD-RUSH CAN CONTINUE</a>, La Quadrature du Net</li>
</ul>
<h3 id="conclusions">Conclusions</h3>
<p>There are clearly risks posed by the widespread adoption of Artificial Intelligence and in no way am I diminishing the work to address these. Risks posed by AI in the here and now are varied but very real. These include but are not limited to:</p>
<ul>
<li>Online political influence operations using AI generated content masquerading as genuine human created content to proliferate disinformation and push agendas.</li>
<li>Privacy concerns arising out of the usage of AI systems to sort through, link together and synthesize vast amounts of data to create detailed social scores and profiles of individuals.</li>
<li>Privacy concerns arising out of the usage of AI in the realm of surveillance, facial recognition and biometric identification and the risks of bias and abuse.</li>
<li>Concerns with Artificial Intelligence&rsquo;s application in armed conflict, regarding accountability and compliance with the legal obligations of war.</li>
<li>Concerns with AI in policing and national security matters, particularly &lsquo;predictive&rsquo; models.</li>
<li>The usage of AI agents to wage cyber wars, and attack critical infrastructure through cyber attacks.</li>
<li>The usage of AI in the commission of cyber crimes ranging from the generation of lifelike child sexual abuse material to AI enhanced phishing and hacks.</li>
</ul>
<p>I am no expert on matters relating to AI and I do not claim to be. What I will claim to have, however, is extensive knowledge on the current surveillance society we all reside in, where we are all subject to the <a href="https://www.theguardian.com/technology/2015/jul/23/panopticon-digital-surveillance-jeremy-bentham">invisible panopticon</a> brought about by the same mega corporations and State agencies (the Surveillance Capitalist - National Security State nexus) that is now developing AI and extensively influencing and guiding the regulation of such technologies. Forgive me if I have a large degree of skepticism towards these companies and institutions and their motivations. I think the record speaks for itself on how they behave and operate. If you think it does not I suggest taking a look at the readings under the <a href="http://localhost:1313/resources/" title="Privacy and Security Resources">Privacy and Security Resources</a> section of my website.</p>
<p>It is my view that ethical and regulatory considerations towards AI systems are not wholly unjustified and in many cases are certainly valid. However, they can, have been and will be utilized to impose limitations designed primarily to concentrate power over such systems in the hands of those who are in the position to benefit from their usage the most. The Surveillance Capitalist - National Security State institutional nexus does not want ordinary people to be able to deploy locally run and open-source AI&rsquo;s, as in such a scenario it would not be capable of extracting people&rsquo;s money, data and <a href="https://nymag.com/intelligencer/2019/02/shoshana-zuboff-q-and-a-the-age-of-surveillance-capital.html">behavioral surplus</a> nor retain their monopolistic grip on the digital domain.</p>
<p>The suggested risks posed by open AI systems and proposals to establish regulatory regimes and oversight bodies complete with licencing (permission) and strict liability schemes that will crush open AI development are purported to be for AI safety and the benefit of society. But this obscures the reality. The above mentioned nexus is not to be trusted, with them pretending to serve the common good under a guise of morality as they pursue their own self interests of profit and informational power, regardless of consequences for the public. This is what I believe to be readily transparent and clear.</p>
<p>This is also raises another question. If Artificial Intelligence systems are indeed an existential threat and far too dangerous for them to be open sourced, democratized and available to the public at large then on what grounds is it not likewise too dangerous for such power to be consolidated in the hand of Big Tech, the Surveillance Capitalists and the National Security State apparatus?</p>
<p>It is my opinion that the ultimate threat posed by AI is not some doomsday extinction event but rather the consolidation of Artificial Intelligence power in the hands of an exclusive high &lsquo;priesthood&rsquo;, without true accountability and transparency. We have seen what the internet looks like today; a locked down, commodified shell of its original aspirations that places us all as economic objects in the relentless drive to extract and monetize ever more behavioral surplus, that is Surveillance Capitalism, while <a href="http://localhost:1313/posts/wearebeingwatched/" title="We are being Watched">we are all being watched</a> under the omniscient eye of Big Brother(s). Artificial Intelligence has the potential to up end this relationship between us and informational power centers or to forever render us as informational commodities. So which will it be? Only time will tell but that future rests upon whether or not AI power is consolidated or dispersed within society.</p>
<hr>
<p><em>&ldquo;The liberty of a democracy is not safe if the people tolerate the growth of private power to a point where it becomes stronger than their democratic state itself. That, in its essence, is Fascism—ownership of Government by an individual, by a group, or by any other controlling private power.&rdquo;</em>  <strong>- <a href="https://www.presidency.ucsb.edu/documents/message-congress-curbing-monopolies">Franklin D. Roosevelt, 32nd President of the United States of America</a></strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "bigtechandai"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>Encryption Under Attack (Yet Again)</title>
      <link>http://localhost:1313/posts/encryptionunderattack/</link>
      <pubDate>Mon, 06 May 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/encryptionunderattack/</guid>
      <description>The global push to undermine your privacy and security through client side scanning.</description>
      <content:encoded><![CDATA[<h3 id="the-crypto-wars">The Crypto Wars</h3>
<p>Since the advent of the ‘<a href="https://www.youtube.com/watch?v=lv8OFSWZkGs">Crypto Wars</a>’ (as in cryptography) starting in the early 1990’s, there has emerged a general global trend of intelligence services, law enforcement agencies and governments pushing back against the proliferation of so called ‘warrant-proof’ encryption: encrypted data that the state is technically unable to access. The <a href="https://www.nytimes.com/2019/07/23/us/politics/william-barr-encryption-security.html">rationale</a> from these entities is that unlike traditional forms of data that are accessible following appropriate judicial safeguards such as a warrant, encrypted information circumvents the rule of law and the legitimacy and capabilities of criminal/ intelligence investigations. Typically invoking the age old ‘<a href="https://www.theguardian.com/technology/2014/oct/09/crypto-wars-redux-why-the-fbis-desire-to-unlock-your-private-life-must-be-resisted">Four Horsemen of the Infocalypse</a>’: a variation of child predators, terrorism, organized crime and money launderers, states have consistently, across the political spectrum, sought to <a href="https://www.schneier.com/blog/archives/2019/12/scaring_people_.html">scare the general public</a> into supporting their encryption undermining efforts using <a href="https://sci-hub.se/https://doi.org/10.1016/j.clsr.2020.105526">oversimplified and damaging narratives</a>.</p>
<p>This <a href="https://www.scientificamerican.com/article/the-encryption-wars-are-back-but-in-disguise/">pushback against encryption</a> has manifested itself as attempts from states worldwide to implement ‘<a href="https://www.justice.gov/olp/lawful-access">lawful access</a>’ mechanisms into encrypted software, in essence mandating backdoors into the software and services that we all use everyday in order to facilitate state access. The notion of granting state institutions decryption powers technologically implemented into mainstream software and services has been lambasted and fiercely opposed by <a href="https://academic.oup.com/cybersecurity/article/1/1/69/2367066?login=false">leading cyber security researchers</a>, <a href="https://www.globalencryption.org/about/members/">civil society groups</a> and <a href="https://iapp.org/news/a/tech-companies-push-back-against-lawmakers-demands-for-encryption-backdoors/">industry</a> for introducing severe cybersecurity and privacy risks, with efforts from lawmakers across liberal democratic states to pass such legislation typically being frustrated. The reasoning from these groups can be summed up as <a href="https://www.lawfaremedia.org/article/back-doors-good-guys-means-back-doors-bad-guys-unpacking-another-claim">the facilitation of backdoor access for the ‘good guys’ invariably necessitates backdoor access for the ‘bad guys’</a> as well. In response to this, states have ramped up efforts to shape public discourse in favor of mandating ‘lawful access’ such as in the <a href="https://www.eff.org/deeplinks/2022/01/uk-paid-724000-creepy-campaign-convince-people-encryption-bad-it-wont-work">UK</a>, <a href="https://www.statewatch.org/media/3804/eu-usa-som-jha-meeting-outcome-7725-23.pdf">the US and the EU</a> with the goal of manipulating public opinion around encryption raising <a href="https://www.globalencryption.org/2023/04/statement-on-eu-us-cooperation-against-encryption/">alarms</a>. See below for a great explainer on the subject of encryption backdoors.</p>
<p>Concerning as this may be, a new paradigm shift in the encryption debate is rapidly emerging: a shift from the traditional attempts to introduce a ‘key under the doormat’ type of backdoor to that of mandating client side scanning (CSS). This shift represents an unprecedented attempt at enlarging the modern surveillance state into the devices and software used by everyone of us. As of this blog posts date legislative proposals that amount to mandatory client side scanning have been implicitly or explicitly put forward in the <a href="https://www.euractiv.com/section/data-protection/news/leak-commission-to-force-scanning-of-communications-to-combat-child-pornography/">European Union</a>, the <a href="https://www.theguardian.com/technology/2023/apr/18/whatsapp-signal-unite-against-online-safety-bill-privacy-messaging-apps-safety-security-uk">United Kingdom</a> and the <a href="https://www.eff.org/deeplinks/2023/04/earn-it-bill-back-again-seeking-scan-our-messages-and-photos">United States</a> with similar rules having already been implemented in <a href="https://www.eff.org/deeplinks/2021/07/indias-draconian-rules-internet-platforms-threaten-user-privacy-and-undermine">India</a>.</p>
<h3 id="what-is-client-side-scanning">What is Client Side Scanning?</h3>
<p>Client side scanning, as described by the <a href="https://www.internetsociety.org/resources/doc/2020/fact-sheet-client-side-scanning/">Internet Society</a>, “broadly refers to systems that scan message contents—i.e. text, images, videos, files—for matches or similarities to a database of objectionable content before the message is sent to the intended recipient.” At first glance this essentially circumvents the encryption process without the breaking of sound cryptography, with content being scanned prior to encryption and transmission locally. Under current governmental narratives client side scanning would be deployed to combat child sexual abuse material and terrorist content <a href="https://arxiv.org/abs/2110.07450">either</a> through the perceptual hashing (comparing) of user uploaded content against databases of known content or through artificial intelligence driven classifiers or what can be classed as predictive models, generated from large datasets by machine learning algorithms.</p>
<p>As to a real world example of how CSS could be implemented we can take the hypothetical example of Signal (note: Signal has stated they <a href="https://signal.org/blog/uk-online-safety-bill/">would not comply</a> with CSS mandates). Imagine you would like to send a message to a friend. Normally the message is end-to-end encrypted which ensures that only you and your friend are able to view it ensuring your confidentiality of communications. Under a CSS regime, before being encrypted and sent, the message would be scanned for objectionable content locally on your device and then encrypted once it has cleared the screening. Should the message, whether it be an image, video file, text based or an audio recording, run afoul of the screening process it would then be blocked and/ or transmitted to the service provider -Signal in this example- and the relevant state authorities for further review.</p>
<p>Client side scanning represents an evolution of the lawful access debate in that the obligations imposed, do not at first glance, require the compromising of encryption standards and security through traditionally proposed lawful access mechanisms. It has thus been seen by many, such as <a href="https://arxiv.org/abs/2207.09506">2 GCHQ cybersecurity chiefs</a>, as a compromise between user privacy and surveillance goals as it is seen to preserve user privacy while detecting only targeted content. This will be analyzed below.</p>
<h3 id="privacy-and-security-vulnerabilities">Privacy and Security Vulnerabilities</h3>
<p>As stated previously systems of client side scanning would necessitate the creation of a monitoring mechanism built into the applications, services and platforms that comprise the modern internet architecture. Such systems have numerous drawbacks upon being analyzed from a security and privacy perspective. These drawbacks can be broadly categorized into three overarching themes: CSS technology’s non-zero false positive rate; created security and privacy vulnerabilities and potential for evasion by knowledgeable adversaries.</p>
<h4 id="non-zero-false-positive-rate">Non-zero False Positive Rate</h4>
<p>Client side scanning technologies have a non-zero false positive rate and false negative rate, with this raising concerns regarding the impact upon the privacy of innocent, law abiding individuals subject to false positives. The <a href="https://arxiv.org/abs/2110.07450">proprietary and ‘black box’</a> nature of perceptual hashing tools and the difficulty in actually gauging their ‘accuracy’ makes determining their false positive rate difficult. With regards to artificial intelligence driven machine learning methods, predictive accuracy rates can arguably be said to be much lower. Language models applied to text content for the purposes of content moderation are difficult to create with a false positive rate “<a href="https://arxiv.org/abs/2210.08958">significantly below 5% to 10%</a>”. Image detection in its current state does not fare better with current sophisticated image-recognition algorithms still <a href="https://twitter.com/ellajakubowska1/status/1539543255309860864">mistaking a dog for a cat</a> and flagging <a href="https://www.nytimes.com/2022/08/21/technology/google-surveillance-toddler-photo.html">innocent content as criminal</a>. This presents a major issue with scanning technology, being described by European Digital Rights in reference to the EU’s CSS proposal as, being “<a href="https://edri.org/wp-content/uploads/2023/05/CSAR-summary-booklet.pdf">hard put to tell the difference between a topless sunbather or a child’s bath-time photo from an abuse scenario, or to infer whether a person is a teenager or just a young-looking adult.</a>”</p>
<h4 id="security-and-data-privacy-vulnerabilities">Security and Data Privacy Vulnerabilities</h4>
<p>In addition to the high risks of false positives, the implementation of CSS into such a plethora of devices, digital services, platforms and applications will undoubtedly create security and privacy vulnerabilities <a href="https://arxiv.org/abs/2110.07450">capable of being exploited across a spectrum of threat models</a>, from nation state attackers to malicious private actors. These threats range from the <a href="https://www.ieee-security.org/TC/SPW2022/ConPro/papers/hintersdorf-conpro22.pdf">framing of victims through hash manipulation</a>, to the underlying CSS being exploited and repurposed for <a href="https://arxiv.org/abs/2212.04107">wire-tap like physical surveillance capabilities</a>. The expanded attack surface on devices, apps and services would likely pose a cybersecurity risk in encrypted environments. These security and privacy risks have lead to <a href="https://arxiv.org/abs/2110.07450">14 globally leading cybersecurity experts</a> to conclude that client side scanning &ldquo;cannot be deployed safely&rdquo; for the purposes of a surveillance system.</p>
<h4 id="easy-evasion-by-knowledgeable-adversaries">Easy Evasion by Knowledgeable Adversaries</h4>
<p>Leading on from this, there is mounting evidence that client side scanning technologies can be defeated by knowledgeable adversaries either through <a href="https://arxiv.org/abs/2106.09820">evading detection</a> or outright avoidance of the entire system of scanning. For example an <a href="https://arxiv.org/abs/2307.03426">encrypted keyboard</a> could be utilized to “encrypt and decrypt messages locally on phone devices when sending and receiving them via IM [instant messaging] applications.” In addition, CSS systems could be easily avoided in their entirety through the use of free (libre) open source software (FLOSS) that does not and would not implement scanning capabilities in order to comply with any scanning obligations. Some examples of this would be the Tor network and browser, Peer-to-Peer networks and a whole host of private messaging applications. In order to enforce client side scanning obligations, states would have to implement a degree of internet censorship a concern that has been raised by the <a href="https://fsfe.org/news/2022/news-20221026-02.html">Free Software Foundation</a>.</p>
<h3 id="aiding-digital-authoritarians">Aiding Digital Authoritarians</h3>
<p>The application and enforcement of client side scanning regimes is likely to have a global impact due to the technical and financial realities of modern software development. Just like the EU’s General Data Protection Regulation has an externalizing regulatory effect it makes sense that many firms would elect to institute CSS worldwide rather than creating separate application builds for individual regions and countries. With alarms being raised about <a href="https://news.un.org/en/story/2022/09/1126671">democratic ‘backsliding’</a> and the rise of <a href="https://www.cambridge.org/core/journals/international-organization/article/abs/digital-authoritarianism-and-the-future-of-human-rights/5027FD3B3C6A3F36A0B26ECBFD9FC061">‘digital authoritarianism’</a> worldwide, client side scanning mandates from liberal democratic states could open the (encrypted) door for states with lesser judicial protection of and respect for the rule of law and fundamental rights to demand and exploit the underlying scanning system to be used for authoritarian repressive purposes.</p>
<p>Furthermore, by attempting to weaken and rebuff strong effective encryption democratic states permit digital authoritarians to rebuff legitimate human rights concerns by pointing to the West. As described by Edward Snowden, <a href="https://edwardsnowden.substack.com/p/all-seeing-i?utm_source=substack&amp;utm_campaign=post_embed&amp;utm_medium=web">in reference to Apple’s similarly proposed CSAM detection system and the risks of authoritarian abuse</a>, &ldquo;this is not a slippery slope. It’s a cliff.&rdquo;</p>
<h3 id="unmitigated-mass-surveillance">Unmitigated Mass Surveillance</h3>
<p>Currently proposed systems of client side scanning, as just covered, have major problems with less than acceptable false positive rates and security vulnerabilities that have major implications for individual privacy and civil liberties. But even if these problems were to be mitigated, client-side scanning technologies shift the screening from <a href="https://arxiv.org/abs/2110.07450">&ldquo;what is shared (the cloud) and what is private (the user’s device)&rdquo; digitally &ldquo;removing any boundary between a user’s private sphere and their shared (semi-)public sphere,&rdquo;</a> ensuring that there will always be the possibility for law enforcement and intelligence services to access previously private information, even in the absence of a warrant or other appropriate judicial safeguards.</p>
<p>The potential for CSS systems to be abused by state actors and exploited through vulnerabilities by both state and non-state entities is also of significant concern due to the highly intrusive nature of client side scanning, which is capable of revealing highly intimate and personal information about users and their devices. These are all major concerns also shared by the UN High Commissioner for Human Rights, with a report concluding that client side scanning technologies could not be &ldquo;<a href="https://documents-dds-ny.un.org/doc/UNDOC/GEN/G22/442/29/PDF/G2244229.pdf?OpenElement">considered proportionate under international human rights law, even when imposed in pursuit of legitimate aims</a>&rdquo;. The concern thus leads on as to how such a system of general client side scanning could be limited in scope to their purported aims and not expand in competence through what Bruce Schneier observes in his book <em>Data and Goliath</em> as &ldquo;the inevitable expansion of power that accompanies the expansion of any large and powerful bureaucratic system&rdquo;; mission creep.</p>
<blockquote>
<p>What is often framed as a debate about moderation of unwanted content in E2EE services is really a discussion about (any) content detection in E2EE. <em>-<a href="https://cdt.org/wp-content/uploads/2021/08/CDT-Outside-Looking-In-Approaches-to-Content-Moderation-in-End-to-End-Encrypted-Systems-updated-20220113.pdf">Center for Democracy and Technology</a></em></p>
</blockquote>
<p>Today’s systems of surveillance in liberal democratic states are primarily used to pursue legitimate but broad aims such as national security and the combating of crime rather than for oppressive control and authoritarian purposes as seen in the <a href="https://theintercept.com/2022/10/05/intercepted-china-surveillance/">People’s Republic of China</a> and other digital authoritarian states. However, this is not a result of underlying differences in surveillance architecture but rather a difference in governance from those that hold power over said systems. You may be inclined to trust your government of today but what about the government which wields the reigns of power tomorrow? “<a href="https://link.springer.com/article/10.1007/s13347-022-00503-9">Even established democracies might decay. There is a risk that surveillance capacities that are used for democratically legitimated purposes today will be used for poorly legitimated purposes in the future</a>.”</p>
<p>Politicians need to understand the technological realities of encryption and avoid simplifying narratives and public fearmongering. The three rules laid out in a paper laying down rules to facilitate open debate about lawful access to strongly encrypted information: <em><a href="https://www.sciencedirect.com/science/article/abs/pii/S026736492030131X">Talking in the Dark</a></em> can serve as a guide and starting point for legislative proposals seeking to tackle the difficulties of digital investigations. These ’rules’ prescribe: 1) Legislation should clearly indicate, without sidestepping the encryption debate through ambiguity or subterfuge, whether it can be utilized to &ldquo;mandate lawful access&rdquo;; 2) officials &ldquo;should not deliberately oversimplify the encryption debate or rely on emotive examples in order to influence public opinion&rdquo;; 3) Judicial safeguards &ldquo;must not be conflated with the safeguards applicable to lawful access solutions in order to lend false legitimacy to unsafe solutions&rdquo;. Adherence to these three rules would ensure a responsible legislative debate that does not result in measures that threaten our privacy, security and ultimately fundamental rights and liberties.</p>
<p>It is my view that the proposed implementations and operation of what can be coined &ldquo;<a href="https://twitter.com/matthew_d_green/status/1524107553248100355">the most sophisticated mass surveillance machinery ever deployed outside of China and the USSR</a>&rdquo; raises one very fundamental question. Do we, as a hyper-digitized society, want a system of highly invasive and total digital surveillance, irrespective of its purpose and intent, to be embedded within all of our devices? To scan and screen all of our private and confidential communications? To exist at all?</p>
<p>I would, of course, argue not.</p>
<hr>
<p><em>Were CSS to be widely deployed, the only protection would lie in the law. That is a very dangerous place to be.</em> <strong>-Bugs in Our Pockets: The Risks of Client-Side Scanning</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "encryptionunderattack"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>The Engineering of Consent: Political Microtargeting</title>
      <link>http://localhost:1313/posts/theengineeringofconsent/</link>
      <pubDate>Mon, 08 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/theengineeringofconsent/</guid>
      <description>The future of political advertising and online manipulation.</description>
      <content:encoded><![CDATA[<h3 id="what-is-online-political-microtargeting">What is Online Political Microtargeting?</h3>
<p>With society becoming increasingly digitized (“the integration of multiple technologies into all aspects of daily life”) the resulting abundance of personal data and information that can be amassed about the individual has only served to be <a href="https://firstmonday.org/ojs/index.php/fm/article/view/4991">exponentially magnified</a>. Corresponding to this rapidly growing and valuable <a href="https://www.weforum.org/agenda/2017/09/the-value-of-data/">‘data economy’</a>, the use of personal data for political purposes has also risen, massively increasing the prevalence of data-driven political campaigns. Amongst the various tools and methods available to apply personal data towards political purposes, it is this posts’ view that online political microtargeting (OPMT) stands out, with its historically unprecedented usage yielding <a href="https://www.tandfonline.com/doi/full/10.1080/07393148.2015.1125119">ramifications</a> for the rights to privacy; electoral fairness and on a broader scale fundamental <a href="https://policyreview.info/data-driven-elections">democratic processes</a> and concepts.</p>
<p>But what is online political microtargeting and how does it impact upon you? OPMT can be described, under scholar <a href="https://www.tandfonline.com/doi/full/10.1080/07393148.2015.1125119">Gorton’s definition</a> as:</p>
<blockquote>
<p><em>“finely honed messages targeted at narrow categories of voters based on sophisticated combinatorial analysis of data garnered from individuals’ demographic characteristics and consumer and lifestyle habits”</em></p>
</blockquote>
<p>Put simply, online political microtargeting <a href="https://www.uva.nl/en/shared-content/faculteiten/en/faculteit-der-maatschappij-en-gedragswetenschappen/news/2020/07/microtargeting.html">“allows political players to send tailored messages to citizens in order to influence them.”</a></p>
<p>The below video offers a great explanation of how political microtargeting works, created by Cambridge Analytica, the (former) firm at the heart of an <a href="https://www.theguardian.com/news/series/cambridge-analytica-files">election interference scandal</a>.</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/lBgHrn-TrD8?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<h3 id="implications-for-individuals-privacy">Implications for Individual’s Privacy</h3>
<p>The widespread use of OPMT, which requires the accumulation, synthesis and utilization of a massive amount of personal data brings with it major inter-connected implications for individual’s privacy. The storing and use of personal data inevitably leads to the risk of data breaches, an all to common occurrence, which severely undermines individual’s privacy, having <a href="https://cdn.ttc.io/s/tacticaltech.org/Personal-Data-Political-Persuasion-How-it-works_print-friendly.pdf">graver impacts</a> when such data leaked is of political nature. One can look at the Republican Party’s 2017 <a href="https://thehill.com/policy/cybersecurity/338383-data-on-198-million-us-voters-left-exposed-to-the-internet-by-rnc-data">data breach</a> of nearly 200 million US citizens personal political data to see that such a threat is very real and present, and is compounded by the fact that personal data can be used in <a href="http://doi.org/10.18352/ulr.420">unpredictable and untoward novel ways</a>. Data breaches, in addition to the mere collection of personal political data, also have broader implications for Democracy, resulting in <a href="https://ssrn.com/abstract=2654213">chilling effects</a>, if people suspect, or are certain, that their internet presence is being tracked and that they do not have adequate online privacy. Privacy is crucial for voters to autonomously and secretly cast their ballot (a cornerstone of the electoral process), but the advent of data-driven elections and OPMT “presents a new privacy-related threat”, one that “leverages personal information to influence choice” (<em>Big Data, Political Campaigning and the Law: Democracy and Privacy in the age of Micro-targeting, page 47)</em>. Adequate privacy is a necessity for the individual to prosper and be shielded from the tyranny of the majority, creating distinct public, quasi-public and private spaces that serve as a prerequisite for <a href="https://paulschwartz.net/wp-content/uploads/2019/01/VAND-SCHWARTZ.pdf">democratic self rule</a>.</p>
<h3 id="implications-for-electoral-fairness">Implications for Electoral Fairness</h3>
<p>The usage of OPMT effects the balance of power between political parties, with the widespread usage of ‘big data’ morphing the political arena into a data-analytic environment with the ability to effectively sort, process and utilize data towards goals being limited to powerful data-rich incumbent institutions. The implications of this are two-fold. First, this environment favors larger, incumbent and moneyed political parties and candidates as a result of the costly nature of using ‘big data’ (although this cost can be argued to be decreasing with time), leading to political success within a democracy being determined by financial and data resources and the ability to use them to effectively microtarget voters. This places smaller and newer parties and candidates at serious <a href="https://scholar.harvard.edu/files/todd_rogers/files/political_campaigns_and_big_data_0.pdf">disadvantages</a>. Secondly, in such a political environment, centers of power are shifted to a <a href="https://utrechtlawreview.org/articles/10.18352/ulr.420">technocratic</a> class of intermediaries that provide such services such as OPMT and the connection of political parties and the electorate, creating political ‘gatekeepers’ not subject to Democratic scrutiny or accountability.</p>
<h3 id="implications-for-civil-discourse">Implications for civil discourse</h3>
<p>The widespread use of OPMT undermines civil discourse, serving to exasperate and create political polarization, fragmenting the democratic concept of the public forum, through the creation of algorithmically manipulated ‘filter bubbles’, also known as ‘echo-chambers’.</p>
<blockquote>
<p><em>We find ourselves in a filter bubble any time we’re only surrounded by views and opinions we agree with, while being sheltered from opposing perspectives. Filter bubbles distort our understanding of the world and hamper our ability to make balanced decisions.</em> <strong>-Eli Pariser, Author of</strong> <em><strong>Filter Bubbles</strong></em></p>
</blockquote>
<p>If the marketplace of ideas becomes fragmented, with the presence of ‘filter bubbles’ leading voters to exclusively concern themselves with political issues that are most relevant to them, public discourse and civil debate will undoubtedly suffer. Voter turnout, although possibly being increased due to this personalized advertising, would revolve around protecting and promoting individualized interests rather than the interests of the voting individuals placed in the context of the whole political community.</p>
<p>In addition, voters deemed to be unsusceptible or unable to be persuaded can be eliminated/ignored as advertising targets, creating a ‘form of categorical inequality in the public sphere’. OPMT further facilitates the fracturing of broadly engaging political topics into ‘wedge issues’ with political entities being able to ‘dog-whistle’ certain positions to sympathizers while simultaneously hiding them from political opponents. Such an example of this would be during the 2018 Brazilian elections with the campaign of Jair Bolsonaro’s use of WhatsApp to microtarget voters arguably promoting political radicalization and polarization leading to the advent of what has been described as <a href="https://www.researchgate.net/publication/338719508_WhatsApp_and_political_instability_in_Brazil_targeted_messages_and_political_radicalisation">‘digital populism’.</a></p>
<p>The threat of foreign actors utilizing OPMT with the aim of electoral interference is also one to <a href="https://www.ivir.nl/publicaties/download/MaastrichtJournalofEuropeanandComparativeLaw_2021_6.pdf">consider</a>. Foreign actors already use popular <a href="https://demtech.oii.ox.ac.uk/wp-content/uploads/sites/12/2019/09/CyberTroop-Report19.pdf">social media platforms</a> in an attempt to manipulate and subvert democratic processes with the increasing use of microtargeting, based on easily purchasable and obtainable personal data, proving to be an effective tool to sow disinformation.</p>
<blockquote>
<p><em>One of the greatest dangers of political microtargeting is that a voters political opinion can be influenced and altered. Political parties can make countless promises to a specific groups of voters and can hide their personalized stance from the general public. This can lead to very different expectations in voters, which politics can never live up to. The result is a polarized society, and individual parties can create advantages for themselves in the election campaign by making contradictory promises.</em> <strong>-<a href="https://noyb.eu/en/political-microtargeting-facebook-election-promise-just-you">noyb.eu</a></strong></p>
</blockquote>
<h3 id="the-engineering-of-consent">The Engineering of Consent</h3>
<p>Leading on from this is perhaps the most dangerous effect that the use of big data and analytical tools such as OPMT brings for Democracy; namely rendering voters manipulable, creating, as <a href="https://firstmonday.org/ojs/index.php/fm/article/view/4901">Tufekci</a> describes with reference to the ‘father of public relations’ <a href="https://archive.nytimes.com/www.nytimes.com/books/98/08/16/specials/bernays-obit.html">Edward Bernays</a>, ‘more effective- and less transparent- “<a href="http://www.fraw.org.uk/data/politics/bernays_1947.pdf">engineering of consent</a>” in the public sphere.’ Through personalized targeting and the use of ‘wedge issues’, political campaigns can be obscure on significant but broadly relevant topics within political discourse while campaigning with vigor and in secrecy on issues that can muster small, but vital voting demographics. As microtargeting is individualized, political messages distributed in such a manner will not be able to be countered and debated through civil discourse. Through the use of ‘cognitive nudges’, as explained by cyber-security researcher Bruce Schneier in <em>A Hackers Mind</em>, the human brain can effectively be ‘hacked’ with microtargeted content, in order to shape opinions, beliefs and to persuade, especially without necessary transparency. Democracy as a workable concept would arguably fall apart if the legitimacy of those elected was to be achieved through ‘tailored, fine-tuned messaging’ manufacturing the consent of the governed.</p>
<blockquote>
<p><em>“The conscious and intelligent manipulation of the organized habits and opinions of the masses is an important element in democratic society. Those who manipulate this unseen mechanism of society constitute an invisible government which is the true ruling power of our country.”</em> <strong>- Edward L. Bernays, <a href="https://archive.org/details/in.ernet.dli.2015.275553/mode/2up">Propaganda</a></strong></p>
</blockquote>
<p>I would highly recommend the below four part series by the BBC that delves into the ideas of Edward Bernays, amongst others, and how they have aided in the ‘engineering of consent’ to shape the current mass consumerist society we live in through the start of psychology-driven advertising campaigns in the 1950’s. Also accessible <a href="https://thoughtmaybe.com/the-century-of-the-self/">here</a> in case of YouTube removal or if you do not want to use that service.</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/fEsPOt8MG7E?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<h3 id="the-future-of-political-advertising">The Future of Political Advertising</h3>
<p><a href="https://www.congress.gov/bill/117th-congress/house-bill/4955">Efforts</a> to <a href="https://edps.europa.eu/data-protection/our-work/publications/opinions/edps-opinion-proposal-regulation-transparency-and_en">curb</a> the use of political microtargeting online are on the <a href="https://edri.org/our-work/whoreallytargetsyou-political-microtargeting-cant-be-ignored-by-the-dsa/">rise</a>. However, focus on this specific use of personal data for electoral purposes should not overshadow similar but more advanced data practices that will certainly degrade political discourse and democratic processes. As the technical capabilities and scope of Artificial Intelligence increases and the power afforded to those who wield it serves to be magnified, the political domain online will become increasingly hard to navigate effectively. Online political microtargeting is evidently a <a href="https://noyb.eu/en/political-microtargeting-facebook-election-promise-just-you">common occurrence</a>, but the concepts and ideas behind the practice can be used in a multitude of more deceptive and insidious ways. One such example would be “Persona bots’’, or Artificial Intelligence programs posing as real human users on social media platforms and online forums/ groups. These programs won’t need to constantly spout propaganda and political messaging, instead acting as normal users with normal online activity which on occasion will post political content in an attempt to sway public opinion.</p>
<p>I will end with a short video from VICE News that really drives the point home. For now all the best and have a brilliant day!</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/ZP3kLe_3uLo?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<hr>
<p><em>One persona bot can’t move public opinion, but what if there were thousands of them? Millions? … AI has the potential to make the future supply of disinformation spreaders infinite.</em> <strong>-Bruce Schneier, A Hackers Mind: How the powerful bend society’s rules and how to bend them back</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "theengineeringofconsent"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>Reclaim your Privacy | Part 3: Escaping the Privacy Paradox</title>
      <link>http://localhost:1313/posts/privacyguide/</link>
      <pubDate>Thu, 04 Apr 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/privacyguide/</guid>
      <description>Part 3 out of 3 on how to protect yourself online and regain control over your privacy.</description>
      <content:encoded><![CDATA[<h3 id="the-private-individual"><strong>The Private Individual</strong></h3>
<p>Are you growing concerned about the increasing concentration, consolidation, and expansion of informational power in the hands of seemingly unaccountable technology corporations and state actors? Do you wish to mitigate the sense of constant digital surveillance and monitoring every day? If so, let this post act as an introductory guide for you.</p>
<p>Following this guide will necessitate effort on your part to educate yourself and keep yourself updated with the latest developments concerning personal digital privacy. Depending on your personal threat model and how far and deep you want to go on your privacy journey some basic technical know how will be required. I will link the sources that I regularly follow at the end of this post as well as point you to helpful resources and online communities.</p>
<p>If you have not already, I would highly advise checking out the previous two posts in this series that deal with: how to effectively create a personal privacy/ security threat model and management strategy and how to increase your digital security. It will be assumed within this post that you have. These can be seen <a href="http://localhost:1313/posts/threatmodel/" title="Threat modelling">here</a> and <a href="http://localhost:1313/posts/securityguide/" title="Security Guide">here</a>.</p>
<p>I cannot stress enough that you don’t have to implement all of the steps found within these guides in order to increase your digital privacy. Certainly do not go nuclear and implement all of these, all at once lest your suffer from burnout, confusion and ultimately go back to the digital products and services you used before. Remember: any step taken towards protecting your digital privacy is worthwhile, but not every step may be worthwhile to you. What may be a sound privacy choice for one individual may not make sense for another. Always keep in mind your threat model and what exactly you are trying to achieve.</p>
<h3 id="user-control">User Control</h3>
<p>Ultimately, it is my opinion that digital privacy is fundamentally underpinned by the notion of user control. By this I am not referring to the ‘privacy’ settings and toggles available on most applications and digital services but rather the concepts of autonomy and self-sovereignty. Many of the recommendations within this introductory guide will not only serve to increase your privacy but also unshackle you from the exploitative surveillance capitalistic business model that drives the modern internet. By using privacy respecting, free and open source software; ‘Big Tech’ mega-corporations will no longer be the gatekeepers to your digital life.</p>
<blockquote>
<p><em>Control does not guarantee privacy but it is an absolute imperative. Privacy cannot be given, it can only be taken.</em></p>
<p><a href="https://www.youtube.com/watch?v=nQ9LR8homt4">-The Hated One</a></p>
</blockquote>
<h3 id="back-to-linddun">Back to LINDDUN</h3>
<p>Applying the LINDDUN threat model is a must if you want to effectively use the below recommendations to become more private online. As such a quick recap is in order. For more detail I refer you to the first post in this series.</p>
<p><strong>Linkability:</strong> As a general rule you want to aim to prevent the different aspects of your digital life from being linked with each other. An example of this would be using email aliasing instead of reusing the same email address across multiple different accounts</p>
<p><strong>Identifiability:</strong> As a general rule you want to avoid being having your real world identity linked to the data that you produce. An example of this would be if you avoid provide personal identifying data to a service, such as an email with your real name or official documentation.</p>
<p><strong>Non-Repudiation:</strong> Privacy and security goals can, on occasion, come into conflict with each other and be mutually exclusive. Put simply non-repudiation is when a “data subject cannot deny they know, have done or have said something.” For things like online banking or logging into your employers network this is vital for security, to verify that only those with authorized access to a service can gain access. However, for other things “non repudiation leads to data subject accountability: when a person is not able to be repudiate an action or piece of information, he can be held accountable (e.g. a whistleblower can be prosecuted)”. If you need to have ‘plausible deniability’/ avoid non-repudiation I would advise you to ask yourself the questions found on LINDDUN GO under this threat category.</p>
<p><strong>Detectability:</strong> Under certain threat models the outright presence of a piece of data can be an issue regardless of the protections afforded to it. Detectability can result in the “deduction of personal data” and be used to “extend a data subject’s profile (linkability) and/ or identify the data subject”. An example of this would be the presence of an individual’s records in a rehabilitation center that if breached would lead adversaries to deduce sensitive health information.</p>
<p><strong>Unawareness:</strong> Often it is the user themselves that poses the biggest threat to digital privacy and security through unawareness of risks. In order to avoid this scenario of unawareness I would advise your PrivSec management strategy be supported by rudimentary research from reputable sources asking the following questions:</p>
<ul>
<li>
<p>Are you adequately informed about the collection and further processing of your personal data?</p>
</li>
<li>
<p>Does the service you are utilizing provide user-friendly privacy controls with privacy by design/ default settings?</p>
</li>
<li>
<p>Does the service you use provide an easy to use way to request, change and/ or remove your personal data?</p>
</li>
<li>
<p>Does the service you are using require your informed consent before any data is collected or processed and can this consent be easily withdrawn?</p>
</li>
</ul>
<p><strong>Non-Compliance:</strong> The final category in the LINDDUN threat model focuses on basic data protection principles, influenced by the EU’s GDPR but best practice in the industry regardless of applicable legislation. You should assess whether the service you are using or are considering using adheres to the basic data protection principles of:</p>
<ul>
<li>
<p>Purpose limitation: A service provider should only collect and process data for an express predetermined purpose.</p>
</li>
<li>
<p>Proportionality: A service provider should only collect and process the amount of data required for the purpose (data minimization/ principle of least privilege)</p>
</li>
<li>
<p>Storage limitation: A service provider should only store data for as long is strictly necessary for the purpose</p>
</li>
</ul>
<p>Now that you have been refreshed on the LINDDUN method of threat modelling we can delve into some recommendations for software, services and practices. Remember to keep these 7 elements in mind when tailoring the services and software you use to your individual threat model.</p>
<h3 id="mobile-recommendations">Mobile Recommendations</h3>
<h4 id="_use-a-secure-and-privacy-respecting-mobile-operating-system-os_"><em>Use a Secure and Privacy Respecting Mobile Operating System (OS)</em></h4>
<h5 id="iphone-recommendations">Iphone Recommendations</h5>
<p>While Apple in recent years has pushed heavily to create a brand image of respecting privacy the reality is a much more nuanced and grey. I would highly recommend the below video for reference.</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/nQ9LR8homt4?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<p>If you decide to stick with Apple’s IOS I would highly recommend you follow <a href="https://www.privacyguides.org/en/os/ios-overview/">this configuration page on Privacy Guides</a> for which features and settings to enable/ disable.</p>
<h5 id="android-recommendations">Android Recommendations</h5>
<p>It is very hard for me to recommend a stock OEM Android operating system. By this I mean an operating system that comes by default preinstalled such as on Samsung, Huawei, Google Pixel phones. While Android at its core may be open source the versions of Android installed on end user devices are a complete privacy nightmare with invasive Google Play Services being baked into the OS and uninstallable apps such as Facebook (shudder) being ever present on your device.</p>
<blockquote>
<p>When you buy an Android phone, the default operating system comes bundled with apps and functionality that are not part of the Android Open Source Project. Many of these apps—even apps like the dialer which provide basic system functionality—require invasive integrations with Google Play Services, which in turn asks for privileges to access your files, contacts storage, call logs, SMS messages, location, camera, microphone, and numerous other things on your device in order for those basic system apps and many other apps to function in the first place. Frameworks like Google Play Services increase the attack surface of your device and are the source of various privacy concerns with Android. - <a href="https://www.privacyguides.org/en/os/android-overview/">Privacy Guides</a></p>
</blockquote>
<p>However there is an exception: installing a non stock custom Android operating system that respects your digital privacy. Some notable and recommended custom Android operating systems all of which are open source are as follows:</p>
<ol>
<li>
<p><a href="https://grapheneos.org/">GrapheneOS</a></p>
</li>
<li>
<p><a href="http://divestos.org">DivestOS</a></p>
</li>
<li>
<p><a href="https://lineageos.org/">LineageOS</a></p>
</li>
</ol>
<p>These are all simple to install but are limited to certain devices. Keep in mind that all custom Android operating systems other than GrapheneOS have security issues due to the requirement for an unlocked bootloader.</p>
<p><a href="https://grapheneos.org/">GrapheneOS</a> is what I would strongly recommend to those seeking to maximize mobile privacy. It has the gold standard of mobile security being <a href="https://x.com/Snowden/status/1588472045960327168">recommended by the likes of NSA whistleblower Edward Snowden</a>, and in recent news beating out IOS and stock Android in security to <a href="https://x.com/GrapheneOS/status/1791833221165965567?t=Oad6u8E41vUtLZobprTgPQ&amp;s=19">Cellebrite attacks</a> (hacking software used by intelligence agencies, law enforcement and criminals). A full in depth review and explanation of this phenomenal operating system warrants its own post so for now I will link <a href="https://grapheneos.org/features">GrapheneOS’s many privacy and security enhancing features.</a></p>
<h4 id="_end-to-end-encrypted-communications-is-a-must_"><em>End-to-end Encrypted Communications is a Must!</em></h4>
<p>Using end to end encryption (E2EE) for your digital communications is a must. E2EE means that only you and the recipient of the message can see the content of the message being sent. See below for an great easy to understand illustration of how E2EE works.</p>


    
    <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube-nocookie.com/embed/c2OkOckSD20?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"
      ></iframe>
    </div>

<p>You may want to shift your conversations to <a href="https://signal.org/">Signal</a> which has identical functionality to WhatsApp, is just as easy to set up and even looks very similar. While WhatsApp is also E2EE, what sets Signal apart from it is in its collection of metadata. <a href="https://www.forbes.com/sites/zakdoffman/2021/01/03/whatsapp-beaten-by-apples-new-imessage-update-for-iphone-users/?sh=3181c6933623">WhatsApp collects data such as: your contacts list; who you chat with, when you chat with them and for how long</a> all while linking this to a Meta advertising identity. While the content of your messages and calls is encrypted this metadata is able to paint a highly accurate image of your social connections and the way that you live your life. Remember the former Director of the CIA and NSA stated in Congressional testimony that <a href="https://www.justsecurity.org/10311/michael-hayden-kill-people-based-metadata/">“we kill people based on metadata”</a>. In contrast to this, Signal only collects your phone number, when you created your account and the time you last logged in as per this recent <a href="https://signal.org/bigbrother/cd-california-grand-jury/">US Federal Subpoena.</a> Even if you manage to convince only your close family and friends to swap to Signal that is still a win. These conversations would undoubtedly be more intimate than those of your extended social network of friends and acquaintances and will certainly benefit from the additional protection Signal provides.</p>
<h4 id="_consider-cutting-out-or-back-on-your-social-media-accounts_"><em>Consider Cutting Out or Back on Your Social Media Accounts</em></h4>
<p>You may want to consider cutting out Big Tech social media such as Instagram, Facebook, TikTok and Twitter. These platform’s applications amass an incredible amount of information on you to profile you and serve you advertisements and content. And this is not limited to just what you do in the application. These platforms track you across the internet such as with Meta’s tracking pixels imbedded in websites or through IP and browser fingerprinting. If you live within the EEA/ EU make sure you send in a GDPR right to be forgotten request if you choose to delete your accounts.</p>
<p>If this is not possible or you are unwilling to part ways with your social media, consider using fake information to create ‘anonymous’ accounts for platforms that permit it such as X or Reddit and limiting the information you provide them. For example don’t use your personal email address or upload an image of yourself/ your location etc. This is made much easier by using aliasing services (covered in depth below). Additionally, you can elect to only access these platforms through a privacy respecting browser as social media apps are notorious for acting similarly to spyware on your device.</p>
<h4 id="_use-a-secure-and-privacy-respecting-web-browser_"><em>Use a Secure and Privacy Respecting Web browser</em></h4>
<p>For mobile browsing I would recommend either Brave Browser on Android with some settings tweaks or Safari on IOS with tweaks. See this page on <a href="https://www.privacyguides.org/en/mobile-browsers/">Privacy Guides</a> for more up to date information on how to configure your browser.</p>
<h4 id="_consider-paying-for-your-sim-in-cash_"><em><strong>Consider Paying for your SIM in Cash</strong></em></h4>
<p>If legally possible and financially prudent you may elect to use a prepaid/ pay as you go number that you can top up with cash at an in person store location. This may be more costly and inconvenient but your mobile number will not be linked to your government identity and your mobile provider will not be able to sell useful information to data brokers and cold callers. Again keep in mind your personal threat model as this step may not be for everyone.</p>
<h4 id="_pay-close-attention-to-application-permissions_"><em>Pay Close Attention to Application Permissions</em></h4>
<p>You should pay very close attention to the permissions that you allow the applications installed on your device to have. By permissions I am referring to whether your installed applications are able to access: wifi, bluetooth, bluetooth LE, locations services, contacts, images and videos, files etc. Ask yourself if an application really needs a permission, for example: are you comfortable with Instagram having access to your entire photo and video gallery?</p>
<p>In recent years mobile operating systems such as IOS have allowed you to select only those files which you would like an application to access. Make use of this feature.</p>
<p>GrapheneOS deserves a mention here in that you are able to control these permissions to a much greater degree compared to other operating systems. With GrapheneOS you are able to: set up storage scopes (create sandboxed folders which applications can see only what you choose to let them); revoke Bluetooth, sensor and WiFi permissions (even before installing apps) amongst many other application <a href="https://en.wikipedia.org/wiki/Sandbox_(computer_security)">sandboxing</a> features.</p>
<h4 id="_reduce-your-attack-surface-and-data-leakage-by-limiting-the-apps-that-you-have-installed-on-your-device_"><em>Reduce your Attack Surface and Data Leakage by Limiting the Apps That You Have Installed on Your Device</em></h4>
<p>Tied in with the above point is the need to limit the amount of applications that you have installed on your device. The more apps you have downloaded the larger your threat vector is for data collection. Go through all of your apps, if there are any that you don’t use very often or at all consider uninstalling them. Many applications can also be accessed from a computer or browser, if possible use that option. This will have the effect of reducing your <a href="https://www.techtarget.com/whatis/definition/attack-surface">attack surface</a> and the overall data collection occurring on your phone. As well it does wonders for peace of mind and productivity to have a decluttered phone in which only those apps you actually need are installed.</p>
<p>Do you really need that McDonalds app for the occasional free Big Mac when the same app is tracking your geolocation and creating a profile of you <a href="https://imgur.com/gallery/mcdonalds-app-tracks-location-info-things-like-psychological-trends-wPoauAF">“reflecting the consumer’s preferences, characteristics, psychological trends, predispositions, behaviour, attitudes, intelligence, abilities, or aptitudes”</a>? Or the <a href="https://www.wired.com/story/tim-hortons-coffee-app-location-data-tracking/">Tim Hortons app that collected constant precise geolocation data on their customers movements and habits</a> in return for an occasional ‘free’ (in my opinion) overpriced and subpar coffee? There are many more examples of this that can be cited but I hope the point is clear. Even the most innocuous applications are siphoning you data constantly to feed the surveillance capitalist digital economy.</p>
<h4 id="_mobile-conclusion_"><em>Mobile Conclusion</em></h4>
<p>If you want to be fully anonymous and ‘untrackable’ you would have to forgo your mobile device entirely, something which is unfortunately not possible in today’s digital world. By using a mobile device you have to accept that you have a tracker in your pocket by the very nature of how mobile cellular technology works. However, by implementing the above steps to fit your threat model, your privacy greatly enhanced compared to someone who has not implemented any of them. Remember, never let perfect be the enemy of good.</p>
<h3 id="desktop-and-laptop-recommendations">Desktop and Laptop Recommendations</h3>
<h4 id="use-linux">Use Linux</h4>
<p>You may want to consider using a Linux distribution instead of MacOS or Windows. With Microsoft announcing the implementation of what can only be described as <a href="https://www.bbc.com/news/articles/cpwwqp6nx14o">literal AI spyware</a> into Windows 11 it has never been a better time to make the swap.</p>
<p>Linux has never been easier to install and get running. Gone are the days of command line installations and driver issues. Linux today is perfectly capable of being installed and used by the average user. Whether you want to use your PC/ laptop for internet browsing, gaming, editing or document writing Linux has never been more accessible and intuitive.</p>
<p>But why use a Linux distribution instead of Windows or MacOS?</p>
<p>Unlike its proprietary (closed source) counterparts, Linux distributions are free and open-source software (FOSS), providing much needed transparency in the age of Big Tech oligopoly. Just take a look at how quickly a <a href="https://arstechnica.com/security/2024/04/what-we-know-about-the-xz-utils-backdoor-that-almost-infected-the-world/">malicious backdoor was discovered and patched.</a> While such an example may make you think Linux is insecure or prone to hacking the fact that the code was open source (available for anyone to view) and very quickly detected and patched before any damage could be done is a testament to the power of FOSS for security and privacy. Contrast this with Windows, MacOS and other proprietary operating systems that intelligence agencies, such as the <a href="https://wikileaks.org/ciav7p1/">CIA, stockpile zero days</a> for (publicly unknown critical security flaws) in which it can take years if ever for these flaws to be discovered.</p>
<p>With Linux, you&rsquo;re not subject to the invasive telemetry and data collection present in Windows and other operating systems. Whereas Windows constantly sends to Microsoft how the operating system is used, with Linux what you do on your machine is no one else’s business. Additionally, Linux distributions offer only the apps you choose to install with no forced app integrations such as Edge, Office365 or Teams, giving you more control over your own device and further reducing the avenues for data collection and telemetry.</p>
<p>So what Linux distribution should you choose?</p>
<p>I would recommend <a href="https://fedoraproject.org/">Fedora</a> or <a href="https://pop.system76.com/">PopOS</a> as they both offer an easy installation, do not require any use of the command line or terminal and are very user friendly. See the <a href="https://www.privacyguides.org/en/desktop/">Privacy Guides section on desktop operating systems</a> for more information about Linux and the privacy benefits of using it.</p>
<h4 id="_use-a-secure-and-private-web-browser-with-good-habits_"><em>Use a Secure and Private Web Browser with Good Habits</em></h4>
<p>Use an open source privacy respecting browser such as privacy ‘hardened’ Firefox (or its forks such as Librewolf or Mullvad Browser) or Brave Browser. Check out <a href="https://www.privacyguides.org/en/desktop-browsers/">Privacy Guides section on desktop browsers</a> for more up to date information and configuration options. Avoid Google Chrome like the plague.</p>
<p>A good habit to get into is to isolate and separate your different digital identities online using different browser profiles or separate browsers entirely. For example a user could use a hardened Firefox for basic internet surfing, content consumption and personal emailing, Brave Browser for school/ college/ university work and Mullvad Browser for digital banking and government bureaucracy. This would have the effect of compartmentalizing the different aspects of your digital life reducing the ability for tracking to occur across different data points. As browser fingerprinting becomes the dominant form of user tracking and more advanced -<a href="https://fingerprint.com/">check this website and be terrified</a>- this habit is essential.</p>
<h4 id="_limit-your-attack-surface_"><em>Limit your Attack Surface</em></h4>
<p>Again, much like this point under the mobile section of this post you should seek to limit the attack surface of your device by limiting the applications you have installed to what you actually need.</p>
<h3 id="general-recommendations">General Recommendations</h3>
<h4 id="_use-a-reputable-and-privacy-respecting-email-service_"><em>Use a Reputable and Privacy Respecting Email Service</em></h4>
<p>When looking for an email service to use you should be picking one that does not scan your messages to serve you targeted adverts or train its AI models (looking at you <a href="https://www.theguardian.com/technology/2021/may/09/how-private-is-your-gmail-and-should-you-switch">Google</a>). Some great options are:</p>
<ol>
<li>
<p><a href="https://proton.me/mail">Proton Mail</a> hosted in Switzerland</p>
</li>
<li>
<p><a href="https://tuta.com/">Tuta</a> hosted in Germany</p>
</li>
</ol>
<p>With these email providers you will be getting less storage than Gmail, however you can pay a very low amount per month/ year to get more. This is to be expected as in these companies cases you are not the product and thus pay with money and not your privacy. Have a look at the <a href="https://www.privacyguides.org/en/email/">Privacy Guides section on email</a> for more in depth information on how to choose the best provider for you.</p>
<p>Keep in mind however that email is fundamentally flawed as a way of communicating securely as it is not end to end encrypted. Avoid using it for anything sensitive (medical records for example) or utilize encryption and password protect the email before sending - a feature available on Proton and Tuta.</p>
<h4 id="_utilize-aliasing-services_"><em>Utilize Aliasing Services</em></h4>
<p>Other than a phone number, email addresses are the current de facto digital identity that people present on the internet. Most people use the same email address for every service and product which comes with the massive drawback of your different digital accounts being able to be easily linked together.</p>
<p>This is where email aliasing services come in. An email aliasing service lets you quickly create a fresh email address for each website you sign up for. These new email addresses then forward incoming mail to your chosen email inbox, keeping your main email address and email provider hidden. See <a href="https://www.privacyguides.org/en/email-aliasing/">this section on aliasing on Privacy Guides</a> for more information and recommended services. This is perhaps one of the most important steps you can do to regain a degree of privacy on the internet by reducing the ability for data brokers to link your digital activities together under a single identity.</p>
<h4 id="_utilize-a-reputable-and-privacy-respecting-vpn-service_"><em>Utilize a Reputable and Privacy Respecting VPN Service</em></h4>
<p>A VPN (Virtual Private Network) routes your internet traffic through the VPN providers servers in an encrypted ‘tunnel’. All this does is shift the trust that you have to give in order to access the internet from your ISP (Internet Service Provider) to the VPN company. Contrary to the VPN industry’s marketing not all threat models require a VPN. Since the <a href="https://www.theguardian.com/us-news/the-nsa-files">2013 Mass Surveillance Disclosures</a> most <a href="https://www.welivesecurity.com/2018/09/03/majority-worlds-top-websites-https/">internet traffic on the most popular websites is now routed through HTTPS (encrypted)</a>, something any modern browser will notify you of (usually a padlock next to the URL) with warnings before accessing a non HTTPS webpage.</p>
<p><img loading="lazy" src="/images/howvpnworks.jpg" alt="How a VPN Works"  />
</p>
<p>So why use a VPN provider for privacy reasons? Other than to get around geolocked content on Netflix for example or censored/ blocked sites, VPN’s are useful in order to shift trust away from your ISP. By using a VPN your ISP is unable to view anything other than that you are connecting to a VPN’s server. This can be useful if you do not want your ISP to see what webpages you are connecting to. If you torrent or access pirated content or are trying to circumvent state censorship then a VPN is a must.</p>
<p>Using a VPN also has the additional benefit of hiding your true IP address from third-party websites and services, helping you blend in to the crowd of other users on the network and preventing IP based tracking.</p>
<p>However keep in mind that a VPN does not provide anonymity. Do not believe VPN company marketing. With a reputable VPN you will most likely be paying with your bank details (although some offer cash and cryptocurrency payments) which creates a paper trail directly to your real world identity. If you really need to be anonymous the <a href="https://www.torproject.org/">TOR</a> browser would be your best bet.</p>
<p>When choosing a VPN provider keep in mind the following. For more depth and recommendations see <a href="https://www.privacyguides.org/en/vpn/">Privacy Guides</a>:</p>
<ul>
<li>
<p>Where is the VPN provider based? Ideally you would want to choose one that is outside of the jurisdiction of the <a href="https://tuta.com/blog/fourteen-eyes-countries">14 Eyes</a>, a group of western countries intelligence agencies. This is due to these countries legally permitting the forced surveillance/ wiretapping of VPN servers without public disclosure.</p>
</li>
<li>
<p>Does the VPN provider have a no logs policy that is regularly audited by outside independent third parties?</p>
</li>
<li>
<p>Is the applications and even server code open source? Having the code used in the VPN applications and servers being open source and viewable by anyone is a must to ensure security and transparency!</p>
</li>
<li>
<p><strong>Stay away from free VPNs!!!!!!</strong> If you are not paying for the product you are the product! While there are exceptions such as ProtonVPN offering a very limited free option, non paid <a href="https://www.top10vpn.com/research/free-vpn-investigations/ownership/">VPNs as a rule are not to be trusted.</a></p>
</li>
<li>
<p>Look into exactly who is behind the VPN provider. As of this year <a href="https://vpnpro.com/blog/hidden-vpn-owners-unveiled-97-vpns-23-companies/">105 popular VPNs on the market are run by just 24 companies, many of them being advertising and/ or adware related.</a></p>
</li>
</ul>
<h4 id="_use-a-cloud-storage-service-that-offers-end-to-end-encryption_"><em>Use a Cloud Storage Service that Offers End-to-end Encryption</em></h4>
<p>Many cloud storage providers require your full trust in them. Google Drive for example <a href="https://www.nytimes.com/2017/09/06/technology/personaltech/security-google-cloud.html">scans all of your files</a> and prevents/ deletes illicit files such as suspected <a href="https://torrentfreak.com/google-drive-uses-hash-matching-detect-pirated-content/">copyrighted content</a>. If your aim is to achieve a modicum of digital privacy this is clearly unacceptable and you may want to swap to an open source end to end encrypted alternative such as <a href="https://proton.me/drive">Proton Drive</a> or self host. See <a href="https://www.privacyguides.org/en/cloud/">Privacy Guides</a> for all your options.</p>
<p>If swapping to a privacy respecting end to end encrypted alternative is not feasible for you due to budgetary or practical reasons you should consider encrypting your files using encryption software like <a href="https://cryptomator.org/">Cryptomator</a> prior to uploading your files. See <a href="https://www.privacyguides.org/en/encryption/">Privacy Guides</a> for more encryption options.</p>
<h4 id="_separate-your-work-education-from-your-personal-life_"><em>Separate Your Work/ Education From Your Personal Life</em></h4>
<p>You should be separating your personal digital life from your work/ schooling. This is even more important if you have software that has to be downloaded or if your work/ educational institute provides you with a device. There are many cases of <a href="https://www.wired.com/story/student-monitoring-software-privacy-in-schools/">schools</a>, <a href="https://www.washingtonpost.com/technology/2019/12/24/colleges-are-turning-students-phones-into-surveillance-machines-tracking-locations-hundreds-thousands/">colleges</a> and <a href="https://www.brookings.edu/articles/how-employers-use-technology-to-surveil-employees/">workplaces</a> using surveillance technology to monitor their students and employees.</p>
<p>As such do not use a company/ school provided phone or laptop for personal matters and vice versa. Or at the very least compartmentalize the two using different browsers/ browser profiles and profiles if on Android.</p>
<h4 id="_use-free-libre-open-source-software-when-possible_"><em>Use Free Libre Open Source Software When Possible</em></h4>
<p>I would highly recommend changing the applications and services you use to free and open source alternatives. These are often just as functional if not more convenient to use due to there typically being less invasive and annoying account creation requirements and online connectivity checks.</p>
<p>Privacy Guides yet again has a great selection of vetted alternatives under their <a href="https://www.privacyguides.org/en/tools/">tools page</a>. Some examples of alternatives you could use are:</p>
<ul>
<li>
<p>LibreOffice instead of Microsoft Office</p>
</li>
<li>
<p>The browsers mentioned previously instead of Chrome</p>
</li>
<li>
<p>A privacy respecting search engine such as DuckDuckGo, Brave or StartPage instead of Google</p>
</li>
</ul>
<p>Most applications will have a FOSS alternative. All you have to do is do an internet search to see what is out there!</p>
<h4 id="_use-privacy-respecting-frontends-for-popular-services_"><em>Use Privacy Respecting Frontends for Popular Services</em></h4>
<p>A frontend is the part of a software or application that users directly interact with. It includes the user interface and experience design elements, enabling users to access the software&rsquo;s functionality.</p>
<p>There are many privacy respecting frontends for popular services that you may use. Using a frontend can offer privacy benefits by you with more control over your data and interactions. Since frontends are often developed independently from the backend services they connect to, they can implement privacy-focused features such as ad-blocking and tracker-blocking. By accessing services through a frontend, you can reduce your exposure to tracking cookies and invasive data collection practices employed by some websites and applications. Additionally, frontends may offer alternative authentication methods or proxying services, allowing users to access content anonymously or without revealing personally identifiable information.</p>
<p>Some great examples are as follows:</p>
<ul>
<li>
<p><a href="https://freetubeapp.io/">FreeTube</a> or <a href="https://invidious.io/">Invidious</a> to replace YouTube on desktop</p>
</li>
<li>
<p><a href="https://newpipe.net/">NewPipe</a> or the amazing <a href="https://grayjay.app/">GrayJay</a> (which will be the topic for a future post) to replace the YouTube application on Android</p>
</li>
<li>
<p><a href="https://github.com/yattee/yattee">Yattee</a> on IOS, MacOS and TvOS</p>
</li>
<li>
<p><a href="https://github.com/pablouser1/ProxiTok/wiki/Public-instances">ProxiTok</a> instead of TikTok</p>
</li>
</ul>
<p>See more on the <a href="https://www.privacyguides.org/en/frontends/">Privacy Guides section on frontends</a>!</p>
<h3 id="resources-for-further-research">Resources for Further Research</h3>
<ol>
<li>
<p><a href="https://www.privacyguides.org/en/">Privacy Guides</a> (an excellent resource for everything privacy and security)</p>
</li>
<li>
<p><a href="https://ssd.eff.org/">Surveillance Self Defense from the EFF</a> (a great resource from a non-profit fighting for privacy rights)</p>
</li>
<li>
<p><a href="https://privsec.dev/posts/">PrivSec.dev</a> (a blog from a highly talented cybersecurity researcher)</p>
</li>
<li>
<p><a href="https://www.youtube.com/@TheHatedOne">The Hated One</a> (high quality video essay YouTube channel focusing on privacy, surveillance and digital matters)</p>
</li>
<li>
<p><a href="https://www.youtube.com/@NaomiBrockwellTV">NBTV</a> (YouTube channel from a non-profit focusing on privacy and digital sovereignty)</p>
</li>
<li>
<p><a href="https://www.youtube.com/@MentalOutlaw">Mental Outlaw</a> (more comedic YouTube channel focusing on digital security, privacy and general technology news)</p>
</li>
<li>
<p><a href="https://www.youtube.com/@sideofburritos">Side of Burritos</a> (YouTube channel focusing primarily on GrapheneOS)</p>
</li>
</ol>
<h3 id="a-final-note-from-me">A final note from me</h3>
<p>With regards to this post I would highly advise that you do some of your own research. While I have tried to highlight the best practices and privacy solutions these are always subject to change. I cannot encompass everything that will make you more secure and private online in any series of posts. I do hope however that this digital privacy guide is of use to you and proves a valuable resource for you. For those seeking to learn more I cannot recommend <a href="https://www.privacyguides.org/en/">Privacy Guides</a> enough!</p>
<p>I also recommend checking out the Privacy and Security <a href="http://localhost:1313/resources/" title="PrivSecResources">resources page</a> on my website for great reading/ watching recommendations and repositories of PrivSec knowledge!</p>
<hr>
<p><em>When people want privacy, they do not want to hide away their information from everyone; instead, they want to share it selectively and make sure that it is not used in harmful ways. Privacy is not all-or-nothing—it is about modulating boundaries and controlling data flow.</em> <strong>-The Myth of the Privacy Paradox, Daniel J. Solove</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "privacyguide"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>Reclaim your Privacy | Part 2: Digital Security</title>
      <link>http://localhost:1313/posts/securityguide/</link>
      <pubDate>Thu, 01 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/securityguide/</guid>
      <description>Part 2 out of 3 on how to protect yourself online and regain control over your privacy.</description>
      <content:encoded><![CDATA[<h3 id="further-down-the-rabbit-hole">Further Down the Rabbit Hole</h3>
<p>The focus for today is on the tangible steps you can take to enhance your digital security. This guide will encompass the types of software you can use, best practices and things to look out for and keep in mind.</p>
<p>In the previous part to this series of posts, I delved into how to craft a simple yet comprehensive privacy and security management strategy. This chiefly involved how to craft an effective threat model: in order to identify what your digital assets are, who your threats are and how you should go about protecting said assets from said threats. Key terminology is also defined as well as some essential privacy and security concepts. Part 1 can be seen <a href="http://localhost:1313/posts/threatmodel/" title="Threat Modelling">here</a> and I would highly recommend referring to it before delving into this post.</p>
<p>Where I have recommended specific software please keep in mind that recommended privacy tools change often. I have chosen to recommend established and long running projects but these can become out of date or insecure as time passes. I would recommend consulting <a href="https://www.privacyguides.org/en/">Privacy Guides</a> for up to date and in depth information on the privacy and security tools that are at your disposal.</p>
<h3 id="basic-security-steps-for-the-average-joe">Basic Security Steps for the Average Joe</h3>
<p>This first tier includes practices and software that everybody concerned about their digital security should implement and make use of. Following these steps will generally not make you more private online but will increase your security from threats such as phishing, hacks and malicious software. See my previous post for the difference between privacy and security.</p>
<p>These actions are fully compatible with devices, services and software you are currently using (Apple, Google, Microsoft etc) and will not require much effort, time investment or research to implement. While putting these steps into action will not lend itself to increasing your privacy, they are a necessary prerequisite for attaining a higher degree of it online. It is impossible to have meaningful privacy gains if your digital life is not properly secured.</p>
<p>Now in no order of importance:</p>
<h4 id="_1-create-strong-unique-passwords-and-use-a-reputable-password-manager_"><em><strong>1. Create Strong, Unique Passwords and Use a Reputable Password Manager</strong></em></h4>
<p>Passwords should contain a minimum of 12 alphanumeric characters (16+ is recommended), should not contain dictionary words and should only be used once per website, application or service. These passwords are of course near impossible to remember and this is why most internet users use the same <a href="https://www.zdnet.com/article/were-all-still-using-the-same-passwords-even-after-theyve-been-breached/">insecure, possibly leaked, recycled passwords</a> for nearly everything online. This is where a password manager comes in.</p>
<p>A password manager stores all of your login information for all of the internet services you use in one application that is secured with a singular ‘master password’. So instead of having to remember dozens of complicated passwords you need to remember just one. Most modern password managers will offer additional features such as autofill, auto password generation and the storing of banking information. I would <a href="https://www.zdnet.com/article/is-it-ok-to-use-your-browsers-built-in-password-manager/">advise against the use</a> of your web browsers built in password manager as these are: typically less secure, have reduced functionality, locks you in to that browsers ecosystem (Google👀) and limits your ability to access your password vault from only that browser.</p>
<p>Most standalone password manager can be used as a standalone app on any of your devices and as an extension within any browser. The most intuitive and easy to use password manager that I would recommend is free and open source <a href="https://bitwarden.com/">Bitwarden</a>, which offers a host of functions including automatic syncing between all your devices. Setup instructions can be found on its <a href="https://www.youtube.com/playlist?list=PL-IZTwAxWO4VKISOqPdMBXAtKBAu0gd4_">YouTube account</a> and a host of other <a href="https://www.pcworld.com/article/1339204/why-i-switched-to-bitwarden-for-my-password-manager.html">tech news sites</a>. For further information and more in depth recommendations see this section of <a href="https://www.privacyguides.org/en/passwords/">PrivacyGuides</a> on password managers and this section on <a href="https://www.privacyguides.org/en/basics/passwords-overview/">passwords</a> more generally.</p>
<p><img loading="lazy" src="/images/bitwarden.png" alt="Bitwarden"  />
</p>
<h4 id="_2-use-multifactor-authentication-mfa_"><em><strong>2. Use Multifactor Authentication (MFA)</strong></em></h4>
<p>Most of your digital accounts and especially critical digital service that you use (anything tied to your banking information or your email for example) should be set up with <a href="https://www.rsa.com/multi-factor-authentication/what-is-mfa/">multifactor authentication</a>. Multifactor authentication can take the form of an additional question posed on login, a text message or email with an OTP (one time password) or a physical authentication key. The best option for both security and convenience is an authenticator app, such as Google Authenticator, Microsoft Authenticator or what I would personally recommend, open source <a href="https://getaegis.app/">Aegis Authenticator</a> if you are on Android. The use of MFA will protect you from unauthorized access to your accounts even if attackers have your login credentials. Combining this with a strong and unique password will vastly increase your security against data breaches and password leaks.</p>
<p>Setting up an MFA app with your accounts is very simple and straightforward and is offered by most major service providers with easy to follow guides a quick internet search away. See the MFA section within <a href="https://www.privacyguides.org/en/multi-factor-authentication/">PrivacyGuides</a> for more in depth information and suggestions.</p>
<h4 id="_3-use-an-adblocker_"><em><strong>3. Use an Adblocker</strong></em></h4>
<p>Despite the protestations of online advertising firms and attempts from <a href="https://arstechnica.com/gadgets/2022/12/chrome-delays-plan-to-limit-ad-blockers-new-timeline-coming-in-march/">Google to limit the functionality of adblockers</a>, using an adblock service is a must in todays digital world. Malicious adverts or ‘<a href="https://www.cisecurity.org/insights/blog/malvertising">malvertising</a>’ are all too common with the even the <a href="https://www.ic3.gov/Media/Y2022/PSA221221">FBI</a> recommending the use of adblocking software. Adblockers work by filtering content that is sent to your device. The added bonus, on top of increased security, is that you won’t have to deal with annoying adverts on your favorite websites such as YouTube!</p>
<p>The easiest way to enable ad filtering is through the only adblocking browser extension I would recommend, the gold standard of content filtering: <a href="https://ublockorigin.com/">Ublock Origin</a>. For basic users, this open source extension, only requires you add the extension to your browser to properly function. For more advanced users see the Ublock Origin <a href="https://github.com/gorhill/uBlock/wiki">wiki</a>. Certain browsers such as <a href="https://brave.com/">Brave</a> block ads by default and require little in the way of setup and are also a good choice.</p>
<p><em>Note: Google is waging a war on adblockers and your adblocking functionality on Chrome may vary as we go into the future. Firefox and/ or Brave are what I would recommend.</em></p>
<h4 id="_4-encrypt-encrypt-and-encrypt-some-more_"><em>4. Encrypt, Encrypt and Encrypt Some More!</em></h4>
<p>I cannot stress enough how important it is to make sure your devices, the services you use and your communication methods are adequately encrypted. Despite the propaganda that governments may spout regarding encryption, it is a vital tool to secure your digital life.</p>
<p>Your devices should be encrypted with a strong password. This ensures that if your device is lost, stolen or subject to an <a href="https://www.howtogeek.com/689599/what-is-an-evil-maid-attack-and-what-it-teaches-us/">evil maid</a> attack the sensitive data contained within it cannot be accessed by a third party. Think of all the personal data that you have stored on your devices: important documents, intimate photos, banking information and more. You would not want this to fall into the wrong hands.</p>
<p>Modern smartphones, both IOS and Android are encrypted by default provided you use a PIN lock, password or some other form of device security. The most secure way to encrypt your phone is by using a strong, unique password but a 6 digit PIN will suffice for most users. Whether your macOS or Windows device is encrypted can vary based on your device model and operating system and can be a bit more complicated.</p>
<p>On macOS you can check if your device is encrypted by looking for ‘FileVault’ under ‘Privacy and Security’ in your settings. See below (may change with future macOS updates).</p>
<p><img loading="lazy" src="/images/macencryptionimage.jpg" alt="MacOS encryption"  />
</p>
<p>On Windows devices this process is a bit more complicated. Windows 10/11 Pro, Enterprise and Education offer BitLocker encryption. Windows 10/11 Home users are limited to Windows Device Encryption and only on supported hardware. Consult the most recent Microsoft documentation as this seems to change often. If your device is unable to utilize Microsoft encryption you can always turn to a third party disk encryption program such as the audited and open source <a href="https://www.veracrypt.fr/en/Home.html">VeraCrypt</a> to secure your device. I would highly recommend doing this if your device does not offer encryption by default.</p>
<p>Linux users probably do not need any advice regarding this but most distributions will offer full disk encryption, probably LUKS, on install. Ensure that this is enabled as this cannot be done post installation other than through 3rd party tools.</p>
<p>With regards to communications try and communicate with people through end-to-end encrypted (E2EE) messaging applications such as Signal or WhatsApp. At least limit the sending of very sensitive and intimate data to those applications that offer E2EE. E2EE ensures that only you and the intended recipient are able to access the content of a sent message.</p>
<h4 id="_5-practice-some-basic-digital-hygiene_"><em><strong>5. Practice some Basic Digital Hygiene!</strong></em></h4>
<p>Just like you wash your hands before eating and after using the toilet (hopefully), it is wise to practice the equivalent online.</p>
<ul>
<li>
<p>Be very careful of what applications and files you download. Always make sure you download from a verified and authoritative source such as the Google Play Store, Windows Store, Apple Store or legitimate websites. For example if you want to download Firefox, download it from mozilla.org or an official app repository and not anywhere else. Keep in mind that downloading applications from official stores is still not 100% safe. The Google Play Store for example has served <a href="https://www.zdnet.com/article/google-play-malware-if-youve-downloaded-these-malicious-apps-delete-them-immediately/">millions of users with malware</a> but this problem is not limited to just <a href="https://www.wired.com/story/apple-app-store-malware-click-fraud/">Android</a>. Always do you own research when downloading new apps, especially ones that are not very popular or are unknown. A good rule of thumb is to check the permissions required from the app. This can be done within the settings of your device or in the app store. A flashlight app does not require access to your call history or contacts for example.</p>
<p><img loading="lazy" src="/images/flashlightappmeme.jpg" alt="appememe"  />
</p>
</li>
<li>
<p>When in doubt don’t click it. If a link on a website seems sketchy it probably is. Rather be safe than sorry!</p>
</li>
<li>
<p>Use fake info when you can. Of course when know your customer (KYC) rules apply, such as for banking, do not do this. By this I refer to the various apps you may download that ‘require’ personal information such as an account on a sports app or a gaming application. There is simply no need for you to be giving out your full name, date of birth and location in order to follow the Rugby! The more info you give out to more entities, the much greater the chance that data will be leaked in a breach.</p>
</li>
<li>
<p><strong>ALWAYS KEEP YOUR DEVICES AND APPLICATIONS UP TO DATE WITH THE LATEST SECURITY PATCHES.</strong> There are countless examples of massively damaging malware attacks that could have been <a href="https://www.zdnet.com/article/wannacry-ransomware-hospitals-were-warned-to-patch-system-to-protect-against-cyber-attack-but-didnt/">avoided if security updates were done in a timely manner.</a> Enable auto updates, especially for security patches.</p>
</li>
<li>
<p>There is typically <a href="https://www.nytimes.com/wirecutter/blog/best-antivirus/">no need for antivirus software</a>. Windows defender and Apples in built software are more than adequate. Modern antiviruses are pretty much redundant, slow down your computer, can be extremely <a href="https://restoreprivacy.com/antivirus-privacy/">privacy invasive</a> and can be vectors for malware in themselves. This goes for mobile phones as well.</p>
</li>
<li>
<p>When connecting to unsecure WiFi networks use a reputable virtual private network (VPN) or at least do not transmit any sensitive data, such as conduct banking, over it.</p>
</li>
<li>
<p>Always check the websites that you visit are legitimate and use HTTPS encryption. This can be checked through looking at the web address and your browser security button within your search bar, a padlock on Chrome for example. If possible enable the option within your web browser to only connect to HTTPS sites. This can be found in Firefox and Brave browser for example.</p>
</li>
</ul>
<hr>
<p><em>&ldquo;People often represent the weakest link in the security chain and are chronically responsible for the failure of security systems.&rdquo;</em>  <strong>-Bruce Schneier</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "securityguide"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>Reclaim your Privacy | Part 1: Threat Modelling</title>
      <link>http://localhost:1313/posts/threatmodel/</link>
      <pubDate>Mon, 08 Jan 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/threatmodel/</guid>
      <description>Part 1 out of 3 on how to protect yourself online and regain control over your privacy.</description>
      <content:encoded><![CDATA[<h3 id="down-the-rabbit-hole">Down the Rabbit Hole</h3>
<p>If you are reading this post it is safe to assume that you are interested, to some degree, in protecting your personal privacy and security (PrivSec) in our age of hyper-digitization.</p>
<p>Strategies to protect your online PrivSec are constantly evolving. Misinformation, conflicting advice and inadequate recommendations of counter-measures to state and private surveillance are rife on the internet, particularly within privacy-focused communities online. Rather than focus on specific software and hardware that you can use to manage your PrivSec, this blog post will focus on establishing and maintaining an effective threat model tailored to your distinct needs as an individual.</p>
<h3 id="a-3-tiered-series-of-posts">A 3 Tiered Series of Posts</h3>
<p>There will be 2 further posts as part of this 3 part series. I have broken down the steps you can take into 3 distinct tiers, each with its own post, which vary in the effort, time and research for you to implement in practice. These will be:</p>
<ol>
<li>
<p>This post - how to create a threat model and actionable privacy and security management strategy</p>
</li>
<li>
<p>A security guide for the average internet user</p>
</li>
<li>
<p>A privacy guide for those seeking to regain their fundamental right to privacy online</p>
</li>
</ol>
<p>The steps that you will take to enhance your digital security and privacy will depend on your personal threat model and your action plan will not fit into any of the three perfectly.</p>
<p>It is all to common in digital privacy related online communities to see such questions along the lines of: “what is the most private email service?” or “should I use Tor?” with varying misinformed answers being given. Such questions are extremely vague with no clear cut answer as privacy solutions will differ based on your personal digital needs. It must be remembered that digital privacy (and anonymity) and security is a spectrum. The recommended actions for an ordinary person who wants greater security from the myriad of threats online will differ from someone who opposes the current model of ubiquitous state/ corporate surveillance and even more significantly from a dissident journalist for example. See below for a serious representation of this spectrum.</p>
<p><img loading="lazy" src="/images/ericmurphyprivspectrum.jpg" alt="Privacy Spectrum"  />
</p>
<p>Credit goes to <a href="https://www.youtube.com/watch?v=H414XdcbC4Q">Eric Murphy</a></p>
<p>I should stress that you should avoid going too hard too fast. By this I mean you should not go completely down the rabbit hole, use Tor exclusively, nuke your social media accounts and retire to a cabin in the woods donning a tinfoil hat. This will lead to you burning out from the sheer scope of trying to become 100% anonymous online (you cant); reading and researching mountains of conflicting recommendations online and the constant inconveniences from the software and services you would give up. Most of those who choose to pursue digital privacy, security and anonymity in this way will inevitably give up and become disillusioned, returning to their old internet habits. This is why threat modelling is so important as a vital first step to begin your privacy journey as you will soon discover.</p>
<h3 id="threat-modelling-101">Threat Modelling: 101</h3>
<h4 id="why-threat-model">Why Threat Model?</h4>
<p>Protecting your digital data in today’s age of hyper connectivity can be tiresome and disorientating. It seems like almost every other day that your personal data is being exposed from services and software that you use <a href="https://www.reuters.com/technology/twitter-hacked-200-million-user-email-addresses-leaked-researcher-says-2023-01-05/">everyday</a> in numerous <a href="https://www.infosecurity-magazine.com/news/toyota-data-leak-customers/">data breaches</a>. <a href="https://www.nytimes.com/2023/01/05/technology/personaltech/lastpass-breach-password-safety.html">Services</a> and <a href="https://www.businessinsider.nl/hacker-breaks-into-smart-home-google-nest-devices-terrorizes-couple-2019-9?international=true&amp;r=US">hardware</a> that are supposedly privacy and security respecting turn out to be <a href="https://www.wsj.com/video/how-the-fbi-tricked-suspects-into-using-messaging-platform-anom/D5A9F66A-A9FF-4BCA-BEFD-3215D674CF2C.html">compromised</a>, become <a href="https://github.com/gorhill/uMatrix">outdated</a>, <a href="https://fossbytes.com/duckduckgo-allows-microsoft-trackers/">do not adequately inform their users</a> about privacy protections or were <a href="https://www.cnet.com/tech/services-and-software/why-you-should-be-skeptical-about-a-vpns-no-logs-claims/">never that secure</a> to <a href="https://www.vice.com/en/article/gvzw5x/secure-messaging-app-wire-stores-everyone-youve-ever-contacted-in-plain-text">begin with</a>. Navigating this ever evolving landscape is confusing and there is no fault in feeling that. For example the DuckDuckGo search engine can still, as of this posts date, be trusted however <a href="https://arstechnica.com/gadgets/2022/08/microsoft-trackers-run-afoul-of-duckduckgo-get-added-to-blocklist/">until very recently</a> the browser could not be recommended from a privacy point of view due to allowing Microsoft trackers without express user consent or knowledge. This case illustrates that simply relying on specific services is a flawed way to maintain and protect your personal PrivSec and that something more is needed, namely a comprehensive privacy and security management strategy: <a href="https://www.cisco.com/c/en/us/products/security/what-is-threat-modeling.html">a threat model</a>.</p>
<h4 id="what-is-a-threat-model">What is a Threat Model?</h4>
<p>In essence a <a href="https://ssd.eff.org/glossary/threat-model">threat model</a> is a comprehensive plan, or management strategy, that at its core aims to identify what your digital assets are, who your threats are and how you should go about protecting said assets from said threats.</p>
<p>The concept of threat modelling is <a href="https://owasp.org/www-community/Threat_Modeling">widely used</a> in the cyber-security field and for good reason. Threats change and so do the tools needed to counteract them. Nothing is ever 100% secure. What is needed is a specific tailored methodology that is as rigorous as you need it to be.</p>
<h4 id="privsec-fundamentals">PrivSec Fundamentals</h4>
<p>Before I delve into the process of creating a threat model, I will go over some basic fundamental knowledge covering some key terminology. If you are more technically adept or already have knowledge in this field feel free to skip this part of the post.</p>
<p><strong>Security, Privacy and Anonymity:</strong> These three terms often get conflated but they differ substantially.</p>
<ul>
<li>
<p><strong>Security</strong> can be described simply as efforts to keep your data secure from malicious third parties. What you define as a malicious third party would depend on your specific threat model.</p>
</li>
<li>
<p><strong>Privacy</strong> can be defined as keeping elements of your <a href="https://proton.me/blog/anonymity-vs-privacy">digital life to yourself</a>, for example, using an end-to-end encrypted messaging service in which the content of what you send is only accessible by you and the recipient. Your Internet Service Provider (ISP) and state intelligence agencies may be able to work out who you are and who you are communicating with but the content of that would be deemed private.</p>
</li>
<li>
<p>A real world example of how these two terms differ and relate would be the use of Google services. Google is renowned in its industry for having among the best security for its users shielding them from malicious third party attacks everyday. However, your data is not private from Google itself. If avoiding state bulk collection and surveillance capitalism is a part of your threat model, using Google services would be <a href="https://www.eff.org/deeplinks/2013/03/new-statistics-about-national-security-letters-google-transparency-report">deemed as insecure</a>.</p>
</li>
<li>
<p><strong>Anonymity</strong> is described as the decoupling of your real identity from your online actions. An example of this would be utilizing the Tor Network. While it can be deduced what you are doing online, being anonymous means that your online presence cannot be attributed to who you are.</p>
</li>
<li>
<p><strong>Further reading:</strong> <a href="https://www.businesstechweekly.com/cybersecurity/data-security/security-privacy/">Security vs. Privacy vs. Anonymity</a></p>
</li>
</ul>
<p><strong>Adversary:</strong> An online actor that you want to protect your digital data from.</p>
<p><strong>Targeted Attacks:</strong> These refer to attacks by malicious parties such as hackers that attempt to gain access to <em>specifically</em> <em>your</em> digital data and devices.</p>
<p><strong>Passive Attacks:</strong> These refer to events and attacks such as widely proliferated malware, database breaches and hacks that affect and are targeted at <em>multiple people and companies</em>.</p>
<p><strong>Service Providers:</strong> These are the entities that act as your gate-keeper to the internet, such as your search engine and browser, email provider, ISP, communication provider and many more.</p>
<p><strong>Doxing:</strong> ‘Doxing’ or public exposure refers to having your personal information available to the public at large online.</p>
<p><strong>Mass surveillance:</strong> The bulk data collection programs operated by law enforcement and intelligence agencies across the world.</p>
<p><strong>Surveillance capitalism:</strong> The current revenue model on the internet of the collection and processing of individual’s personal data by tech corporations and data brokers for the purpose of profit, typically seen through the use of highly personalized advertising.</p>
<p><strong>Assets:</strong> The elements of your digital life that you want to protect.</p>
<p><strong>Threats:</strong> The entities that you want to protect your assets from.</p>
<h3 id="establishing-an-effective-threat-model">Establishing an Effective Threat Model</h3>
<p>Establishing your effective PrivSec threat model revolves around five key questions. It is important to take your time in thoroughly answering them, taking heed what it is exactly that you want out of your efforts.</p>
<h4 id="1-what-is-it-exactly-that-you-want-to-protect">1. What is it Exactly That You Want to Protect?</h4>
<p>First you will need to figure out what elements of your digital life, or assets, you want to put effort in protecting. These assets can be limited to certain sensitive parts of your digital identity such as an anonymous messaging account or your search engine queries or more generally encompass all the personal digital information that you produce by nature of being connected online.</p>
<p>In order to do this I would advise making a list:</p>
<ol>
<li>
<p>Identifying your assets that you want to protect</p>
</li>
<li>
<p>Identifying where it is stored</p>
</li>
<li>
<p>Identifying who has access to it</p>
</li>
<li>
<p>Identifying what stops others from accessing it</p>
</li>
</ol>
<p>The digital data that you produce is generally split into two classes: <strong>content</strong> and <strong>metadata</strong> and you should, when making a list of your assets, factor in this categorization.</p>
<p>Content refers to your actual digital content, whether it be the words used in a message or a post online while metadata refers to data about data, including but not limited to I.P addresses, geo-location data and the ‘URLs’ of websites you visit online. Neither is more important than the other from a PrivSec viewpoint, <a href="https://www.youtube.com/watch?v=HO6fNDMGRmg">as is often touted</a>, as both types of data about you can paint an intimate picture about your life, who you are, your daily activities, who you interact with and much more. The ability of metadata to provide actionable information about an individual is clearly elucidated by former NSA and CIA director General Michael Hayden when he testified to Congress: <a href="https://abcnews.go.com/blogs/headlines/2014/05/ex-nsa-chief-we-kill-people-based-on-metadata">“we kill people based on metadata.”</a></p>
<p>Depending on the level of effort you personally want to invest you may want to create a diagram including what entities have your personal data, where this data is stored and what third parties it can be shared with as seen below. Much of this data can be found in the privacy policies and terms and conditions for any given service. I would recommend using <a href="https://tosdr.org/">‘Terms of Service; Didn’t Read’</a> for this unless you enjoy sifting through legalese. I won’t judge ;). Such an index of your data will help you see if the data collected by an entity is truly necessary and proportional to its purposes.</p>
<p><img loading="lazy" src="/images/threatmodelentitydatatable.jpg" alt="Threat Model Table 1"  />
</p>
<h4 id="2-what-do-you-want-to-protect-it-from">2. What do You Want to Protect it From?</h4>
<p>The next stage of creating your personal threat model involves sorting out and identifying exactly who and what your threat adversaries are. Depending on whether your aim is security, privacy or anonymity this step will differ radically from person to person. Under the most extreme threat models, such as if you are trying to avoid state and corporate surveillance, even actors with legitimate access, such as Google, can be a threat.</p>
<p>For simplicity’s sake threat actors/ adversaries can be divided into three groups:</p>
<ol>
<li>
<p><strong>External Adversaries:</strong> Threat actors external to the systems you use, such as hackers, criminal groups or state institutions.</p>
</li>
<li>
<p><strong>Organizational Adversaries:</strong> Entities, such as a company or service provider you use, which manages your data in ways in which you do not approve. This also covers <a href="https://www.telegraph.co.uk/news/2021/07/12/exclusive-extract-facebooks-engineers-spied-women/">rogue employees</a> abusing your personal data.</p>
</li>
<li>
<p><strong>Receiving Parties:</strong> Entities that can have your personal data shared to them, or the receiving end of your communications (such as message recipients).</p>
</li>
</ol>
<p>Once you have done this it is time to move onto the sub-step of what threats you want to protect your data from. This is where the <a href="https://www.linddun.org/linddun-go-categories">LINDDUN</a> model of privacy/ security threats proves highly useful. Use this methodology to assess the following threats based on the information gathered previously in your threat model journey.</p>
<p><strong>Linkability:</strong> The ability of an adversary to “sufficiently distinguish whether two IOI [items of interest] are linked or not, even without knowing the actual identity of the subject of the linkable IOI”. An example would be using the same login credentials, such as an email, across multiple different services. This can lead to inferences, singling out of an individual and identifiability which <a href="https://www.justsecurity.org/81547/with-roe-v-wade-at-risk-digital-surveillance-threatens-reproductive-freedom/">can</a> and <a href="https://www.forbes.com/sites/thomasbrewster/2021/10/04/google-keyword-warrants-give-us-government-data-on-search-users/">has</a> lead to unwanted potentially <a href="https://tcf.org/content/report/disparate-impact-surveillance/">discriminatory practices</a>.</p>
<p><strong>Identifiability:</strong> The capability of an adversary to “sufficiently identify the subject within a set of subjects”. This occurs when “data items can be linked to the identity of the data subject, with a certain probability.” An example of this would be if you provide personal identifying data to a service, such as an email with your real name or official documentation.</p>
<p><strong>Non-Repudiation:</strong> Privacy and security goals can, on occasion, come into conflict with each other and be mutually exclusive. Put simply non-repudiation is when a “data subject cannot deny they know, have done or have said something.” For things like online banking or logging into your employers network this is vital for security, to verify that only those with authorized access to a service can gain access. However, for other things “non repudiation leads to data subject accountability: when a person is not able to be repudiate an action or piece of information, he can be held accountable (e.g. a whistleblower can be prosecuted)”. If you need to have ‘plausible deniability’/ avoid non-repudiation I would advise you to ask yourself the questions found on LINDDUN GO under this threat category.</p>
<p><strong>Detectability:</strong> Under certain threat models the outright presence of a piece of data can be an issue regardless of the protections afforded to it. LINDDUN defined this as “being able to sufficiently distinguish whether an item of interest (IOI) exists or not.” Detectability can result in the “deduction of personal data” and be used to “extend a data subject’s profile (linkability) and/ or identify the data subject”. An example of this would be the presence of an individual’s records in a rehabilitation center that if <a href="https://healthitsecurity.com/news/healthcare-data-breach-at-pa-rehab-center-impacts-130k">breached</a> would lead adversaries to deduce sensitive health information.</p>
<p><strong>Unawareness:</strong> Today it is highly common for your personal data to be stored by services in ‘the cloud’ (a fancy and obscure way of saying on another entity’s computer) subject to their data protection policies and procedures. Services fall victim to <a href="https://www.linddun.org/disclosure-of-information">data breaches and hacks</a> everyday, exposing the personal information of <a href="https://www.statista.com/statistics/273550/data-breaches-recorded-in-the-united-states-by-number-of-breaches-and-records-exposed/">millions</a>. You may trust a specific service provider but this does not change the reality. The more time that your data is stored on another entity’s computer systems the higher the likelihood is that it will be leaked and such a breach for the purposes of any threat model should be assumed to be inevitable. While less common attacks on individual’s personal devices are also a threat. This leads us to the concept of <strong>Unawareness</strong>. User unawareness is one of the biggest threats to an individual’s security and privacy and the main cause of privacy and security tools and methodologies failing. In today’s hyper-digitized age most individuals think nothing of handing over their personal data to a manifold of different applications, service providers etc. When a data subject is “unaware if, or unable to intervene in, the collection and further processing of their personal data” the end result can lead to a violation of their fundamental rights. This happens through a:</p>
<ol>
<li>
<p><strong>Lack of transparency/ predictability:</strong> if “a data subject is unaware of collection and/ or processing of personal data related to them.” An example of this would be if there are no notices of data collection in the first place or of third party sharing.</p>
</li>
<li>
<p><strong>Lack of intervenability:</strong> if **“**a data subject cannot access or manage their own personal data (including managing access settings).” An inability for individual’s to access, change or remove data or update privacy settings would be an example of this.</p>
</li>
</ol>
<p>In order to avoid this scenario of unawareness I would advise your PrivSec management strategy be supported by rudimentary research from reputable sources asking the following questions:</p>
<ul>
<li>
<p>Are you adequately informed about the collection and further processing of your personal data?</p>
</li>
<li>
<p>Does the service you are utilizing provide user-friendly privacy controls with privacy by design/ default settings?</p>
</li>
<li>
<p>Does the service you use provide an easy to use way to request, change and/ or remove your personal data?</p>
</li>
<li>
<p>Does the service you are using require your informed consent before any data is collected or processed and can this consent be easily withdrawn?</p>
</li>
</ul>
<p><strong>Non-Compliance:</strong> The final category in the LINDDUN threat model focuses on basic data protection principles, influenced by the EU’s GDPR but best practice in the industry regardless of applicable legislation. You should assess whether the service you are using or are considering using adheres to the basic data protection principles of:</p>
<ul>
<li>
<p><strong>Purpose limitation:</strong> A service provider should only collect and process data for an express predetermined purpose.</p>
</li>
<li>
<p><strong>Proportionality:</strong> A service provider should only collect and process the amount of data required for the purpose (data minimization/ principle of least privilege)</p>
</li>
<li>
<p><strong>Storage limitation:</strong> A service provider should only store data for as long is strictly necessary for the purpose</p>
</li>
</ul>
<p>Again a diagram can prove very useful depending on the level of effort you want to invest. When an answer to a question leads to a threat in a corresponding category for a service you utilize, you can easily mark it off as seen in the below example. This would require the previous diagram. I would also highly recommend you ‘play’ <a href="https://www.linddun.org/go">LINDDUN GO</a> while doing this for a complete, fully exhaustive, intuitive and easy to follow experience to ensure that your threat model is tailored to you.</p>
<p><img loading="lazy" src="/images/linduntable.png" alt="Threat Model Table 2"  />
</p>
<h4 id="3-how-likely-is-it-that-you-will-need-to-protect-it">3. How Likely is it That you Will Need to Protect it?</h4>
<p>This stage of creating your personal threat model revolves around the ideas of risk, threats and capabilities. In this stage, heavily linked to the previous step, you should list the threats you are going to treat seriously and those that are too harmless or rare to worry about.</p>
<blockquote>
<p>“the likelihood that a particular threat against a particular asset will actually occur. It goes hand-in-hand with capability. While your mobile phone provider has the capability to access all of your data, the risk of them posting your private data online to harm your reputation is low.” <em>-EFF’s Surveillance Self-Defense</em></p>
</blockquote>
<p>An important note to take into account is the difference between the threat event that may occur and the likelihood that it will occur. Remember, assessing risk is highly subjective and personal. What one person may deem as an acceptable amount of risk may be unacceptable to you based on your threat model and vice-versa.</p>
<h4 id="4-what-are-the-consequences-of-failure">4. What are the Consequences of Failure?</h4>
<p>This stage of the threat modelling process asks what are the potential ramifications of a breach to your threat model. You should note down and list what adversaries could do with your data for this step.</p>
<blockquote>
<p>“Security planning involves understanding how bad the consequences could be if an adversary successfully gains access to one of your assets. To determine this, you should consider the <a href="https://ssd.eff.org/glossary/capability">capability</a> of your adversary. For example, your mobile phone provider has access to all your phone records. A hacker on an open Wi-Fi network can access your unencrypted communications. Your government might have stronger capabilities.” <em>-EFF’s Surveillance Self-Defense</em></p>
</blockquote>
<h4 id="5-how-much-effort-are-you-willing-to-go-through-to-mitigate-the-threats-and-consequences">5. How Much Effort are You Willing to go Through to Mitigate the Threats and Consequences?</h4>
<p>The amount of time, effort and resources you are willing to dedicate to creating an effective personal PrivSec management strategy will primarily be determined by steps three and four. Depending on your level of risk and your perceived threats, you may want to go through greater or lessor efforts. For example a lawyer or journalist working on matters related to national security or within a repressive regime will have a considerably different and more exhaustive threat model than a family member who regularly posts amusing videos online.</p>
<p>Once you have completed this stage you would have successfully created a personally tailored threat model!</p>
<p><strong>The next step would be to mitigate these threats that you identified.</strong> <strong>This will be done in the follow up posts to this series!</strong></p>
<h3 id="every-threat-model-is-different">Every Threat Model is Different</h3>
<p>I can’t stress enough that every individual’s PrivSec threat model is different. All these steps are not necessarily to be taken in order as they are all highly interconnected and inter-related. It is my hope that this post has proven useful and informative to you and has offered a decent introductory guide into how to effectively establish a personal privacy and security management strategy. Even if you choose not to implement this methodology today or tomorrow you should be equipped, should you need it, for whatever the future may hold.</p>
<p>For a more in depth look into how to create an effective threat model and PrivSec management strategy I would highly recommend the sources that were heavily consulted with in the creation of this post which can be seen at the end of this post.</p>
<h3 id="main-sources-used">Main Sources Used</h3>
<ul>
<li>
<p><a href="https://ssd.eff.org/">EFF’s Surveillance Self-Defense</a></p>
</li>
<li>
<p><a href="https://www.privacyguides.org/">PrivacyGuides</a></p>
</li>
<li>
<p><a href="https://www.linddun.org/">LINDDUN</a></p>
</li>
<li>
<p><a href="https://www.threatmodelingmanifesto.org/">Threat Modeling Manifesto</a></p>
</li>
<li>
<p><a href="https://www.youtube.com/watch?v=6AXkJ3dot2s">How To Protect Your Online Privacy With A Threat Model | Tutorial 2022</a>, The Hated One, YouTube</p>
</li>
</ul>
<hr>
<p><em>“Security is a process, not a product.”</em> <strong>-Bruce Schneier</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "threatmodel"
})
</script>


]]></content:encoded>
    </item>
    <item>
      <title>We are Being Watched: Privacy, Security and the Law in a Hyper-Digitized Age</title>
      <link>http://localhost:1313/posts/wearebeingwatched/</link>
      <pubDate>Tue, 26 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/wearebeingwatched/</guid>
      <description>We are being watched. Every second of everyday&amp;hellip;</description>
      <content:encoded><![CDATA[<h3 id="the-current-reality">The Current Reality</h3>
<p>We are currently living in an age of hyper-digitization and constant internet connectivity, in which every online and increasingly physical action we take creates digital traces in the form of data; data about us. Whilst the use of this data brings with it many novel solutions to societal problems and is certainly increasing efficiency and efficacy in the realms of business, governance and many more, there is an enormous trade-off that many are simply not aware of, or fully understand the gravitas of. This trade-off is multi-faceted but can be broken down into the core concepts of <a href="https://www.privacyguides.org/basics/common-threats/">privacy and security</a>.</p>
<p>We are all being watched. Every second of every day <a href="https://www.ohchr.org/sites/default/files/Documents/HRBodies/HRCouncil/RegularSession/Session23/A.HRC.23.40_EN.pdf">state</a> and <a href="https://www.economist.com/leaders/2017/05/06/the-worlds-most-valuable-resource-is-no-longer-oil-but-data">non-state</a> actors are engaged in the practice of <a href="https://privacyinternational.org/learn/mass-surveillance">mass surveillance</a>, consistently and ubiquitously collecting, processing and retaining our personal data on the permanent record. This trend, <a href="https://theintercept.com/2015/11/17/u-s-mass-surveillance-has-no-record-of-thwarting-large-terror-attacks-regardless-of-snowden-leaks/">dubiously justified</a> under ‘national-security’ and crime prevention grounds; or plainly for the profit of a slew of multi-billion and <a href="https://www.reuters.com/markets/europe/tech-giants-dominate-wall-streets-trillion-dollar-club-2021-12-09/">trillion</a> dollar corporations engaging in <a href="https://journals.sagepub.com/doi/10.1177/1095796018819461">“Surveillance Capitalism”</a>, is not going anywhere anytime soon.</p>
<p>Cyber-criminals, leveraging the nature of our hyper-digitized society and the burgeoning <a href="https://www.oracle.com/internet-of-things/what-is-iot/">‘internet-of-things’,</a> in which everything from mobile phones to basic household appliances are embedded with sensors and online connectivity, exploit technical and human security vulnerabilities to steal, defraud and <a href="https://apnews.com/article/technology-hacking-europe-cf8f8eee1adcec69bcc864f2c4308c94">cost lives</a>, amounting to the loss of <a href="https://cybersecurityventures.com/hackerpocalypse-cybercrime-report-2016/">trillions</a> globally. This acute and ever-present threat is magnified by <a href="https://www.nsa.gov/Signals-Intelligence/Overview/">signals intelligence</a> (SIGINT) <a href="https://www.propublica.org/article/the-nsas-secret-campaign-to-crack-undermine-internet-encryption">attacks</a> on web standards, <a href="https://www.computerweekly.com/news/252523028/GCHQ-experts-back-scanning-of-encrypted-phone-messages-to-fight-child-abuse">encryption</a> and security in an effort to ‘stockpile’ <a href="https://www.schneier.com/blog/archives/2016/08/the_nsa_is_hoar.html">vulnerabilities</a>, known as <a href="https://csrc.nist.gov/glossary/term/zero_day_attack">‘zero-days’</a>, for offensive purposes, with the result of making us all less safe online.</p>
<p>Legislatures, with some notable exceptions such as the <a href="https://commission.europa.eu/law/law-topic/data-protection/data-protection-eu_en">European Union</a> (barring recent legislative proposals that <a href="https://www.euractiv.com/section/data-protection/news/leak-commission-to-force-scanning-of-communications-to-combat-child-pornography/">raise alarms</a>), are either asleep at the wheel, <a href="https://www.justice.gov/archive/ll/subs/detailed_vote_2001.htm">complicit</a> in the <a href="https://www.nytimes.com/2015/10/28/opinion/europe-is-spying-on-you-mass-surveillance.html">growing state of surveillance</a> or <a href="https://reason.com/2022/01/21/anti-tech-antitrust-bill-draws-criticism-from-all-sides/">unable</a> to effectively regulate private and public surveillance activities. Intelligence agencies flagrantly <a href="https://www.theguardian.com/us-news/2020/sep/03/edward-snowden-nsa-surveillance-guardian-court-rules">violate the law</a> suffering little to no consequences or oversight ensuring such practices <a href="https://freedom.press/news/understanding-the-new-cia-mass-surveillance-scandal/">continue</a>, <a href="https://www.usatoday.com/story/opinion/2018/01/19/james-clappers-perjury-dc-made-men-dont-get-charged-lying-congress-jonathan-turley-column/1045991001/">lie</a> to democratically elected representatives and the public and <a href="https://edition.cnn.com/2022/01/27/politics/avril-haines-government-secrets/index.html">over-classify</a> their surveillance activities eroding public trust in state institutions. <a href="https://www.theguardian.com/world/2013/jun/09/edward-snowden-nsa-whistleblower-surveillance">Whistle-blowers</a>, acting in the public interest and exposing these hidden activities, are criminalized under antiquated espionage laws, with no ability to raise a <a href="https://www.justiceinitiative.org/voices/why-snowden-won-t-get-public-interest-defense-he-deserves">public-interest defense</a>, threatening <a href="https://www.theguardian.com/media/2022/nov/28/media-groups-urge-us-drop-julian-assange-charges">press-freedoms</a> globally. While many of the examples cited refer to the USA’s National Security Agency (NSA), the modern surveillance state extends far beyond <a href="https://privacyinternational.org/learn/five-eyes">any one nation state</a> or selection of <a href="https://www.nytimes.com/2020/01/24/opinion/sunday/surveillance-capitalism.html">corporations</a>.</p>
<p>While public sentiment has shifted, with a majority of <a href="https://www.pewresearch.org/internet/2015/05/20/americans-attitudes-about-privacy-security-and-surveillance/">Americans</a> and <a href="https://wayback.archive-it.org/12090/20190630043525/https://ec.europa.eu/digital-single-market/en/news/eprivacy-consultations-show-confidentiality-communications-and-challenge-new-technologies-are">Europeans</a> gauging personal privacy as highly important, most individuals do not know how to effectively protect their online data and privacy from public and private entities. This is exasperated by big tech companies that hold an effective oligopoly over the hardware and software that we all use having user surveillance as a core monetization strategy. They mislead consumers and users about the <a href="https://www.cpomagazine.com/data-privacy/investigation-finds-apple-app-tracking-rules-may-be-ineffective-idfa-blocked-but-apps-frequently-access-other-identifiers/">extent that they protect their privacy</a> and in many cases are <a href="https://www.theguardian.com/world/2013/jun/06/us-tech-giants-nsa-data">party to</a> (as seen below), an <a href="https://www.businessinsider.com/the-cia-made-larry-ellison-a-billionaire-2014-9">effective arm</a> and <a href="https://theintercept.com/2020/07/14/microsoft-police-state-mass-surveillance-facial-recognition/">intrinsically linked</a> to SIGINT intelligence efforts, being actors in what can only be described as the <a href="https://www.aclu.org/other/surveillance-industrial-complex">‘surveillance-industrial complex’</a>.</p>
<p><img loading="lazy" src="/images/nsaprismcollectiondetails.jpg#center" alt="PRISM"  />
</p>
<blockquote>
<p><em>“Majorities</em> [referring to the U.S.A] <em>think their personal data is less secure now, that data collection poses more risks than benefits, and believe it is not possible to go through daily life without being tracked” -</em> <a href="https://www.pewresearch.org/internet/2019/11/15/americans-and-privacy-concerned-confused-and-feeling-lack-of-control-over-their-personal-information/">Pew Research Center</a>, November 15 2019</p>
</blockquote>
<p>One just has to look at the prevalence of the <a href="https://mashable.com/article/fbi-agent-webcam-jokes">“FBI Agent”</a> internet gag to see that pervasive surveillance and the death of online privacy has been normalized and is accepted as part and parcel of everyday online life.</p>
<h3 id="how-this-impacts-us-all">How This Impacts Us All</h3>
<p>The modern news cycle is filled to the brim with examples of rampant SIGINT <a href="https://www.theguardian.com/world/2021/jul/18/revealed-leak-uncovers-global-abuse-of-cyber-surveillance-weapon-nso-group-pegasus">state abuse</a> and <a href="https://www.theguardian.com/world/interactive/2013/nov/01/snowden-nsa-files-surveillance-revelations-decoded#section/1">overreach</a> as well as near constant corporate <a href="https://www.theguardian.com/business/2022/sep/29/optus-data-breach-everything-we-know-so-far-about-what-happened">data breaches</a> and hacks that affect your <a href="https://arstechnica.com/information-technology/2022/12/lastpass-says-hackers-have-obtained-vault-data-and-a-wealth-of-customer-info/">most personal data</a>, far more than can possibly be covered in any single article or blog post. What can be said is that the trend is clear. When operating in secret, protected by classification and under the cloak of ‘national security’ and other broad and vague public-interest justifications, executive branch intelligence agencies run <a href="https://www.theguardian.com/commentisfree/2013/jul/15/crux-nsa-collect-it-all">amok</a> with their intelligence gathering powers. No greater indictment is needed than from the NSA itself, with its internal motto at the time of the 2013 mass surveillance disclosures: “sniff it all, know it all, collect it all, process it all, exploit it all and partner it all.”</p>
<p><img loading="lazy" src="/images/nsacollectionposture.jpg#center" alt="NSA Collection Posture"  />
</p>
<p>This has extremely dangerous implications for Democracy, the rule of law and our fundamental rights, liberties and freedoms that the majority of readers undoubtedly benefit from. It is common to hear variations of “I have nothing to hide, so nothing to fear” when discourse on mass surveillance practices by for-profit corporations and mainly state agencies is had. This premise, at first glance, appears reasonable. If the intended targets of the bulk-collection of our data are terrorists, criminals and others seeking to inflict harm to society, surely the innocent need not worry. However, there are a plethora of flaws in this argument’s underlying reasoning.</p>
<p>Such an argument presupposes that privacy, a civil and political right that you are entitled to, recognized in <a href="https://www.ohchr.org/en/instruments-mechanisms/instruments/international-covenant-civil-and-political-rights">international law</a>, across the <a href="https://commission.europa.eu/aid-development-cooperation-fundamental-rights/your-rights-eu/eu-charter-fundamental-rights_en">European Union</a> and <a href="https://www.coe.int/en/web/human-rights-convention#">Europe as a whole</a>, in the <a href="https://www.law.cornell.edu/wex/privacy">United States of America</a> and various <a href="https://unctad.org/page/data-protection-and-privacy-legislation-worldwide">other states</a> is something reserved only for criminals. This is wrong. Ordinary, law abiding individuals have many legitimate reasons to want to keep elements of their lives private, whether it be their political affiliations, health data or financial records. Recent developments in the USA surrounding <a href="https://www.reuters.com/world/us/us-supreme-court-overturns-abortion-rights-landmark-2022-06-24/">abortion rights</a>, regardless of personal views on the legality of abortion, showcases that today’s law abiding individuals can turn into tomorrow’s ‘criminals’ overnight and that digital privacy can act as a <a href="https://www.usatoday.com/story/tech/2022/05/10/internet-data-abortion-law-privacy-safety/9643935002/">shield</a> for those in need of protection.</p>
<blockquote>
<p>“History is littered with examples of how data gathered even under neutral or positive auspices can later be exploited for regrettable, and sometimes terrifying, ends. Censuses conducted in Europe in the early twentieth century that asked people to note their religious affiliation later helped the SS identify the largest pockets of Jews in each country they occupied during World War II” <em>-Surveillance State: Inside China’s Quest to Launch a New Era of Social Control, Josh Chin and Liza Lin</em></p>
</blockquote>
<p>This argument also inverts the presumption of innocence, a basic tenet of Democracy, due-process and the rule of law. The purpose of such a foundational principle is to check abuses of state power against the individual, but under what can be described as <a href="https://www.theguardian.com/technology/2015/jul/23/panopticon-digital-surveillance-jeremy-bentham">panopticon</a> levels of surveillance this has been perverted, arguably leading to profound <a href="https://pen.org/research-resources/chilling-effects/">chilling effects</a> on society. A chilling effect is, simply put, when people are aware that they are being watched, they act differently, something that has been <a href="https://lawcat.berkeley.edu/record/1127413?ln=en">quantitatively observed and verified</a>.</p>
<blockquote>
<p>“The state bears the burden of showing there is a good reason for suspicion, not the other way around. The refrain “nothing to hide” should not be a license for sweeping government surveillance… Living under the constant gaze of government surveillance can produce long-lasting social harm: if citizens are just a little more fearful, a little less likely to freely associate, a little less likely to dissent – the aggregate chilling effect can close what was once an open society.” <em>-ACLU, <a href="https://www.aclu.org/news/national-security/you-may-have-nothing-hide-you-still-have-something-fear">You May Have &lsquo;Nothing to Hide&rsquo; But You Still Have Something to Fear</a></em></p>
</blockquote>
<p>My fear is that the <a href="https://www.vice.com/en/article/bvge5q/snowden-warns-governments-are-using-coronavirus-to-build-the-architecture-of-oppression">“Architecture of Oppression”</a> is, for the most part, silently and without broad public knowledge, being created across liberal democratic states. With the advent of complex <a href="https://www.atlanticcouncil.org/blogs/geotech-cues/the-west-china-and-ai-surveillance/">artificial intelligence</a> based <a href="https://www.reuters.com/world/china/china-uses-ai-software-improve-its-surveillance-capabilities-2022-04-08/">surveillance tools</a>, such an architecture for societal control and power has become unprecedented in it’s scope and ability to peer into the most intimate and minute details of all of our lives.</p>
<p>Today’s systems of surveillance in liberal democratic states are primarily used to pursue legitimate but broad aims such as national security and crime prevention or the generation of profits by private corporations (which comes with <a href="https://theconversation.com/big-tech-surveillance-could-damage-democracy-115684">risks</a> that will be discussed in later posts), rather than for oppressive tyrannical control as seen in the <a href="https://theintercept.com/2022/10/05/intercepted-china-surveillance/">Peoples Republic of China</a>. However, this is not a result of underlying differences in surveillance architecture but rather a difference in governance from those that hold power over said systems. It can be argued that systems of governance in liberal democracies would prevent such a dystopia from manifesting but I believe this to disregard the nature of power <a href="https://theintercept.com/2019/10/10/fbi-nsa-mass-surveillance-abuse/">wielded without accountability</a> and to be <a href="https://www.euractiv.com/section/digital/news/spyware-systematically-used-by-some-eu-governments-meps-find/">wholly naive</a>.</p>
<p>Those who can be trusted to hold the reigns of power today may not hold them tomorrow. Governments can change but the underlying surveillance apparatus will not. Do we want such an immense source of power to be present at all in society, always bringing with it the threat of untold abuse? I end this point with a poignant quote from Edward Snowden, NSA whistle-blower and a catalyst for the 2013 mass surveillance disclosures.</p>
<blockquote>
<p>“There is, simply, no way, to ignore privacy. Because a citizenry’s freedoms are interdependent, to surrender your own privacy is really to surrender everyone’s. You might choose to give it up out of convenience, or under the popular pretext that privacy is only required by those who have something to hide. But saying that you don’t need or want privacy because you have nothing to hide is to assume that no one should have, or could have to hide anything – including their immigration status, unemployment history, financial history, and health records. You’re assuming that no one, including yourself, might object to revealing to anyone information about their religious beliefs, political affiliations and sexual activities, as casually as some choose to reveal their movie and music tastes and reading preferences. Ultimately, saying that you don’t care about privacy because you have nothing to hide is no different from saying you don’t care about freedom of speech because you have nothing to say. Or that you don’t care about freedom of the press because you don’t like to read. Or that you don’t care about freedom of religion because you don’t believe in God. Or that you don’t care about the freedom to peaceably assemble because you’re a lazy, antisocial agoraphobe. Just because this or that freedom might not have meaning to you today doesn’t mean that that it doesn’t or won’t have meaning tomorrow, to you, or to your neighbor…” <em>-Edward Snowden, Permanent Record</em></p>
</blockquote>
<h3 id="what-can-be-done">What Can Be Done?</h3>
<p>The situation is not completely bleak and I would urge readers to not succumb to the fatalist idea that there is nothing to be done and that the future is one of minimal to no digital privacy and security. There are multiple courses of action individuals, you, can start doing right now:</p>
<ul>
<li>
<p>You can write to your elected representatives stressing the need for effective regulation of the data-collection industry and real transparent oversight of state intelligence capabilities.</p>
</li>
<li>
<p>You can support and vote for political parties and politicians who raise concerns about the state of digital society and are committed as part of their platform to meaningful change.</p>
</li>
<li>
<p>You can support the work of non-profits fighting for transparency and accountability from public and private entities, whether it be a donation or simply keeping up to date on their work. A non-exhaustive list would be:</p>
<ul>
<li>
<p><a href="https://privacyinternational.org/">Privacy International</a> (UK and global)</p>
</li>
<li>
<p><a href="https://bigbrotherwatch.org.uk/">Big Brother Watch</a> (UK)</p>
</li>
<li>
<p><a href="https://edri.org/">European Digital Rights</a> (EU)</p>
</li>
<li>
<p><a href="https://noyb.eu/en">None of Your Business</a> (EU)</p>
</li>
<li>
<p><a href="https://www.eff.org/">Electronic Frontier Foundation</a> (USA)</p>
</li>
<li>
<p><a href="https://epic.org/">Electronic Privacy Information Center</a> (USA)</p>
</li>
</ul>
</li>
<li>
<p>You can educate yourself on how to reclaim your digital privacy and improve your online security. A good starting point for anyone serious about implementing personal privacy and security protection strategies would be:</p>
<ul>
<li>
<p><a href="https://www.privacyguides.org/">Privacy Guides</a></p>
</li>
<li>
<p><a href="https://ssd.eff.org/">Surveillance Self-Defense</a> offered by the Electronic Frontier Foundation</p>
</li>
<li>
<p>Research into the surveillance capabilities, practices and actions of public and private institutions</p>
</li>
</ul>
</li>
</ul>
<hr>
<p><em>“Privacy is an inherent human right, and a requirement for maintaining the human condition with dignity and respect. It is about choice, and having the power to control how you present yourself to the world.”</em> <strong>-Bruce Schneier, Data and Goliath: The Hidden Battles to Collect Your Data and Control Your World</strong></p>
<hr>
<p><em>Disclaimer: I do not, by any means, claim to be an expert in matters relating to privacy, security and law or offer what can be construed as guaranteed fool-proof advice. What I do offer is an insight into these matters from someone who is highly invested in personal privacy/ security themselves and who is studying technology law at the level of higher education.</em></p>
<hr>
<div style="text-align: center" id="custom-substack-embed"></div>


<script>
  window.CustomSubstackWidget = {
    substackUrl: "privseclaw.substack.com",
    placeholder: "example@yourmail.com",
    buttonText: "Subscribe Now!",
    theme: "custom",
    colors: {
      primary: "#0FA4AF",
      input: "#3E3E3E",
      email: "#15CAD8",
      text: "#3E3E3E",
    },

    

  };
</script>
<script src="https://substackapi.com/widget.js" async></script>
<hr>
<script type="text/javascript" src="https://latest.cactus.chat/cactus.js"></script>
<link rel="stylesheet" href="https://latest.cactus.chat/style.css" type="text/css">
<div id="comment-section"></div>
<script>
initComments({
  node: document.getElementById("comment-section"),
  defaultHomeserverUrl: "https://matrix.cactus.chat:8448",
  serverName: "cactus.chat",
  siteName: "<privseclaw.info>",
  commentSectionId: "wearebeingwatched"
})
</script>


]]></content:encoded>
    </item>
  </channel>
</rss>
